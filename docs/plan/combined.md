# AshTrail - Consolidated Documentation

*This document was automatically generated by consolidating 31 individual markdown files.*

---

<!-- FILE: 0. AshTrail - Table of Contents.md -->

<a id="0-ashtrail---table-of-contents"></a>

[1. Project Overview](#1-project-overview)
[2. Technology Stack](#2-technology-stack)
[3. Application Structure](#3-application-structure)
[4. Domain Model](#4-domain-model)
[5. Logging System](#5-logging-system)
[6. State Management](#6-state-management)
[7. Data Persistence](#7-data-persistence)
[8. Authentication & Accounts](#8-authentication-&-accounts)
[9. UI Architecture](#9-ui-architecture)
[10. Analytics & Aggregation](#10-analytics-&-aggregation)
[11. Error Handling & Observability](#11-error-handling-&-observability)
[12. Configuration & Environments](#12-configuration-&-environments)
[13. Testing Strategy](#13-testing-strategy)
[14. Deployment & Distribution](#14-deployment-&-distribution)
[15. Assumptions & Open Questions](#15-assumptions-&-open-questions)
[16. Future Extensions](#16-future-extensions)
[17. Performance & Scalability](#17-performance-&-scalability)
[18. Data Integrity & Consistency](#18-data-integrity-&-consistency)
[19. Time, Locale, and Timezone Handling](#19-time,-locale,-and-timezone-handling)
[20. Security Model](#20-security-model)
[21. Permissions & OS Integration](#21-permissions-&-os-integration)
[22. Notifications & Reminders](#22-notifications-&-reminders)
[23. Import - Export](#23-import---export)
[24. Developer Workflow](#24-developer-workflow)
[25. Coding Standards](#25-coding-standards)
[26. Documentation Conventions](#26-documentation-conventions)
[27. Feature Flags & Experimental Work](#27-feature-flags-&-experimental-work)
[28. Migration & Backward Compatibility](#28-migration-&-backward-compatibility)
[29. Observability & Diagnostics](#29-observability-&-diagnostics)
[30. Decommissioning & Data Deletion](#30-decommissioning-&-data-deletion)
---

<!-- FILE: 1. Project Overview.md -->

<a id="1-project-overview"></a>

## 1. Project Overview

### 1.1 Purpose

#### 1.1.1 Problem Statement

AshTrail provides a **local-first, transparent, and controllable logging system** for personal substance usage (initially smoking/vaping), with accurate timestamps, structured metadata, and long-term analytics—without relying on opaque third-party tracking apps or cloud-only data silos.

The project prioritizes **data correctness, ownership, and auditability** over social, gamified, or wellness-coaching features.

##### 1.1.1.1 User Pain Points

- Existing habit-tracking apps:
  - Hide or abstract raw data
  - Do not support offline-first operation
  - Make exporting or inspecting full datasets difficult
- Cloud-only solutions:
  - Risk data loss or lock-in
  - Obscure sync behavior and conflict resolution
- Manual tracking:
  - Is error-prone
  - Loses temporal accuracy
  - Does not scale to long-term analysis
- Multi-account scenarios:
  - Are poorly handled or unsupported
  - Often assume a single global identity

###### 1.1.1.1.1 Limitations of Existing Solutions

- No deterministic local source of truth
- Limited schema extensibility
- Analytics derived from transformed data rather than raw events
- Inability to trace how a specific data point was recorded, stored, and synced

---

### 1.2 High-Level Goals

#### 1.2.1 Offline-First Logging

- All logs must be creatable, viewable, and queryable **without network access**
- Local persistence is authoritative
- Cloud sync is additive and optional

#### 1.2.2 Multi-Account Support

- Support multiple user accounts on a single device
- Each account has:
  - Independent local storage
  - Independent sync state
  - No implicit data sharing
- Account switching must not mutate or merge data

#### 1.2.3 Data Ownership & Transparency

- Users can:
  - Inspect raw logs
  - Understand derived analytics
  - Export data in structured formats
- No hidden aggregation, scoring, or normalization without explicit definition

---

### 1.3 Non-Goals

#### 1.3.1 Explicitly Out-of-Scope Features

The following are explicitly not goals of AshTrail:

- Social feeds or sharing
- Health or medical advice
- Addiction treatment or coaching
- AI-driven behavioral recommendations
- Gamification (streaks, rewards, badges)

---

### 1.4 Target Users

#### 1.4.1 Single-User Assumptions

- Primary use case is a single individual per account
	- No collaborative or shared logging
- Data models assume:
	- One logical owner per dataset
	- No concurrent multi-device edits (conflicts handled conservatively)
##### Assumptions
- Multi-user analytics or shared timelines are not required.

---

### 1.5 Architectural Principles

#### 1.5.1 Offline-First
- Local database is the system of record
- Network availability must not affect core functionality
- Sync processes must be resumable and idempotent

#### 1.5.2 Deterministic State
- Application state must be derivable from:
	- Stored data
	- Explicit user actions
- No hidden background mutations
- Same inputs must always yield the same outputs

#### 1.5.3 Explicit Data Models

- All persisted data has:
	- Defined schema
	- Typed fields
	- Clear ownership and lifecycle
- Derived data must reference its source inputs
- Migrations must be explicit and versioned

---

### Open Questions / Assumptions to Validate

##### Assumptions

- Smoking/vaping is the only intended log category.
- Firestore is the planned remote backend unless an alternative free option becomes available.
- Users can perform CRUD operations on all log data.
- Cross-device concurrent editing support is very low priority.

##### Open Questions
- If logs are editable (CRUD), what is the required audit behavior?
	- Last-write-wins with optional metadata.
- If Firestore changes, what is the portability requirement?
	- Abstracted remote adapter
- If cross-device edits occur despite low priority, what is the minimum acceptable conflict behavior?
	- Last-write-wins
#### Open Questions / Validation Needed

- "No concurrent multi-device edits (conflicts handled conservatively)" conflicts with "cross-device concurrent editing is very low priority" (not necessarily "not supported"). Cross-device edits are:
	- Allowed but handled minimally (best-effort conflict strategy).
---

<!-- FILE: 2. Technology Stack.md -->

<a id="2-technology-stack"></a>

## 2. Technology Stack

### 2.1 Frontend

#### 2.1.1 Flutter

##### 2.1.1.1 Version Constraints

###### Purpose
- Flutter is used to build a single codebase targeting mobile platforms with a reactive UI and strong state isolation.

###### Current State
- Flutter version: **3.22.x** (confirmed from project context)
- Dart SDK: aligned with Flutter 3.22.x constraints

###### Constraints
- Code must remain compatible with:
  - Flutter stable channel
  - Dart language features available in Flutter 3.22.x
- Avoid experimental or beta-only Flutter APIs.
- Prefer Material 3-compatible widgets where applicable.

###### Assumptions
- The project will track Flutter stable releases conservatively.
- Breaking Flutter upgrades will be gated behind manual validation.

###### Open Questions
- Is a Flutter upgrade cadence defined (e.g., quarterly, annual)?
- Is web support intentionally excluded or deferred?

---

### 2.2 State Management

#### 2.2.1 Riverpod

##### 2.2.1.1 Provider Types Used

###### Providers Observed / Intended
- `Provider`
  - Stateless dependencies (config, formatters, utilities).
- `StateProvider`
  - Simple mutable UI state (toggles, filters, selections).
- `StateNotifierProvider`
  - Core domain state (logs, sessions, accounts).
- `FutureProvider`
  - Async reads (initial loads, Firestore fetches).
- `StreamProvider`
  - Live Firestore listeners (where enabled).

###### Rationale
- Riverpod chosen over Provider/BLoC due to:
  - Compile-time safety
  - Explicit dependency graph
  - Testability without widget trees
  - Clear separation of UI and domain logic
- `StateNotifier` preferred for:
  - Predictable state transitions
  - Centralized mutation logic
- Providers scoped to features rather than global singleton usage.

###### Assumptions
- No direct mutation of state outside notifiers.
- UI layers are consumers only.

###### Open Questions
- Are `AsyncNotifier` / Riverpod 2.x patterns in use or planned?
- Is provider auto-disposal enabled consistently?

---

### 2.3 Local Persistence

#### 2.3.1 Hive

##### 2.3.1.1 Schema Management

###### Purpose
- Hive provides offline-first local persistence for:
  - Log entries
  - User/session metadata
  - Cached Firestore records

###### Schema Characteristics
- Box-per-domain model (e.g., logs, accounts, settings).
- Typed adapters for all persisted models.
- Explicit versioning via adapter changes.

###### Migration Strategy
- No implicit migrations.
- Schema changes require:
  - New adapter version
  - Manual migration logic on app startup (if needed)
- Data loss on incompatible schema changes is acceptable only if explicitly documented.

###### Constraints
- Hive boxes must open before any provider depends on them.
- Avoid storing derived or redundant data.

###### Assumptions
- Hive is the single source of truth when offline.
- Firestore sync reconciles against Hive state.

###### Open Questions
- Is there a formal adapter versioning policy?
- Are destructive migrations acceptable for any domains?

---

### 2.4 Remote Persistence

#### 2.4.1 Firebase Firestore

##### 2.4.1.1 Collection Strategy

###### Purpose
- Firestore acts as the canonical remote store for:
  - Logs
  - User accounts
  - Cross-device synchronization

###### High-Level Structure
- User-scoped collections
- Log entries stored as flat documents (no deep nesting)
- Timestamps stored in Firestore-native formats

###### Design Constraints
- Reads optimized for:
  - Time-range queries
  - Descending timestamp ordering
- Writes optimized for append-heavy workloads.

##### 2.4.1.2 Environment Separation

###### Environments
- Development
- Production

###### Separation Mechanism
- Distinct collections or collection prefixes per environment.
- Environment selected at runtime via build configuration.

###### Assumptions
- No cross-environment data access.
- Dev data is disposable.

###### Open Questions
- Are separate Firebase projects used, or only collection-level separation?
- Is there an enforced schema contract for Firestore documents?

---

### 2.5 Authentication

#### 2.5.1 Firebase Auth

##### 2.5.1.1 Account Switching Model

###### Purpose
- Support multiple user accounts within a single app installation.

###### Model Characteristics
- Firebase Auth used for identity and session tokens.
- Local account registry stored in Hive.
- Active account context determines:
  - Firestore paths
  - Local data filtering
  - UI state

###### Switching Flow
1. User selects or adds an account.
2. Firebase Auth session is refreshed or swapped.
3. Providers invalidate scoped state.
4. Hive and Firestore contexts rebind to the active account.

###### Constraints
- No shared state between accounts.
- Account switching must be deterministic and reversible.

###### Assumptions
- Refresh tokens are managed explicitly (custom refresh logic exists).
- Offline account switching is supported for already-known accounts.

###### Open Questions
- Is simultaneous multi-account sync allowed or blocked?
- What is the expected behavior when a refresh token expires?

---

### 2.6 Build & Tooling

#### 2.6.1 Flutter Toolchain

###### Tooling
- Flutter SDK (stable)
- Dart CLI
- Firebase CLI (for config and deployment)
- Platform-specific build tools:
  - Xcode (iOS)
  - Android Studio / Gradle (Android)

###### Constraints
- Builds must be reproducible from a clean checkout.
- No reliance on global, undocumented scripts.

###### Assumptions
- CI/CD integration is planned but not mandatory for local builds.

###### Open Questions
- Is there a documented CI pipeline?
- Are build flavors used beyond dev/prod?

#### 2.6.2 Platform Targets

###### Supported Targets
- Android
- iOS
- Web

###### Explicitly Out of Scope (for now)
- Desktop (Windows/macOS/Linux)

###### Assumptions
- Mobile-first UX decisions are acceptable.
- Platform-specific code is isolated behind abstractions.

###### Open Questions
- Is tablet-specific UI support required?
	- No
- Is desktop support a future goal or explicitly excluded?
	- Excluded

---

### 2.7 Open Questions / Validation Needed

- Local persistence: is **Hive** still the chosen local database, or has the project moved (or is moving) to **Isar** for offline storage?
	- We are using Hive since Isar is not supported on web
- Account switching: does the “custom refresh logic” exist in the current codebase, or is it planned/in progress?
	- Planned
- Remote environment separation: is dev/prod separation implemented via:
  - separate Firebase projects, or
  - collection/prefix separation within a single project?
	  - Different users in the same database
- Firestore schema: is there a documented/enforced schema contract (validation, versioning, required fields) for documents?
	- Not yet
---

<!-- FILE: 3. Application Structure.md -->

<a id="3-application-structure"></a>

## 3. Application Structure

### 3.1 Folder Layout

#### 3.1.1 `lib/`

The `lib/` directory is the root of all Dart source code for the application. It is organized to enforce separation of concerns, feature isolation, and controlled dependency flow.

High-level structure (conceptual):

- `lib/core/` — cross-cutting, dependency-free infrastructure
- `lib/features/` — self-contained application features
- `lib/main.dart` — application entry point (not documented here)

---

##### 3.1.1.1 `core/`

The `core/` directory contains foundational building blocks that are shared across all features.

Characteristics:
- Must not depend on any feature module
- Should remain stable over time
- Contains abstractions, utilities, and shared primitives
- Safe to import from anywhere in the app

Typical responsibilities include:
- Logging interfaces
- Time/date abstractions
- Result and error modeling
- Shared constants
- Shared value objects
- Low-level helpers with no business meaning

---

###### 3.1.1.1.1 Cross-Cutting Concerns

Cross-cutting concerns are concerns that affect multiple parts of the application and should not belong to any single feature.

Examples (conceptual, not exhaustive):
- Logging
- Time access
- Serialization helpers
- Error modeling
- Environment configuration
- Identifiers and shared types

Rules:
- Must not reference feature code
- Must be deterministic and side-effect–controlled
- Should expose interfaces rather than concrete implementations when possible
- Should be usable in tests without Flutter bindings

Assumptions:
- Cross-cutting utilities are pure Dart where possible.
- Flutter-specific dependencies are avoided in `core/`.

Open questions:
- Should `core/` be split further into submodules (e.g., `core/logging`, `core/time`)?
	- Yes
- Should enforcement be automated via lint rules or folder-level checks?
	- Yes

---

##### 3.1.1.2 `features/`

The `features/` directory contains all user-facing and domain-specific functionality.

Each feature is isolated and owns:
- Its state
- Its models
- Its logic
- Its UI
- Its internal utilities

Features must not depend on one another directly.

---

###### 3.1.1.2.1 Feature Isolation Rules

Each feature:
- Lives in its own directory under `lib/features/`
- Does not import from sibling feature directories
- Communicates only through:
  - Shared contracts in `core/`
  - Explicit dependency injection
- Can be removed without breaking unrelated features

Recommended internal structure per feature (example):
- features/<feature_name>/
- data/
- domain/
- presentation/
- state/
- widgets/

Rules:
- Feature-local helpers must not be promoted to `core/` unless reused by multiple features
- Shared behavior should be abstracted upward, not copied
- Feature code should assume other features do not exist

Assumptions:
- Riverpod is used to manage feature-level state (documented elsewhere)
- Each feature exposes its public API explicitly

Open questions:
- Should feature boundaries be enforced via package structure or lint rules?
	- Whichever is easier to implement
- Should features expose a single public entry file?
	- Unsure what this is asking

---

### 3.2 Feature-Based Architecture

The project uses a feature-based architecture rather than a layer-only architecture.

Each feature encapsulates:
- Data access
- Business rules
- State
- UI wiring

This reduces cross-feature coupling and improves testability.

---

#### 3.2.1 Feature Boundaries

A feature boundary defines what a feature owns and what it may access.

Boundaries enforce:
- Clear ownership of logic
- Predictable dependency direction
- Easier refactoring and removal

A feature may:
- Import from `core/`
- Import Dart and Flutter SDK libraries
- Use dependency injection to receive shared services

A feature may not:
- Import another feature directly
- Reach into another feature’s internal folders
- Share mutable global state

Assumptions:
- Features communicate indirectly through shared abstractions or events.
- Cross-feature coordination is minimal and explicit.

Open questions:
- Will any “orchestration” layer exist above features?
	- Most likely
- Should cross-feature communication use events, services, or callbacks?
	- Follow best practice

---

### 3.3 Dependency Direction

Dependency direction is strictly enforced to avoid cyclic or hidden coupling.

Allowed dependency flow
	- core  ←  features
Never:
	- features → features
	- core → features

---

#### 3.3.1 Allowed Dependencies

| Source     | Can depend on |
|------------|----------------|
| core       | Dart SDK only |
| features   | core, Dart SDK, Flutter SDK |
| main/app   | core, features |

Additional rules:
- Dependency inversion should be preferred when behavior varies
- Shared abstractions live in `core`
- Concrete implementations live in features or app wiring

Assumptions:
- Dependency injection is used to bind implementations at runtime
- Static globals are avoided where possible

Open questions:
- Is a DI container being used explicitly (e.g., Riverpod providers)?
- Should feature registration be centralized?

---

### 3.4 Shared Utilities

Shared utilities live under `core/` and must follow strict constraints:
- Deterministic behavior
- No feature awareness
- Minimal side effects
- Clear contracts

---

#### 3.4.1 Logging

Purpose:
Provide a consistent, centralized logging abstraction usable across all layers.

Responsibilities:
- Define logging interfaces or helpers
- Normalize log levels
- Provide structured log output
- Avoid direct coupling to a logging backend

Typical capabilities:
- Debug / info / warning / error levels
- Tagged or scoped logs
- Optional structured metadata

Constraints:
- Must not depend on feature code
- Must be safe to call from anywhere
- Should support replacement or redirection of output

Assumptions:
- A logging abstraction exists or will exist in `core`
- Actual output targets (console, file, remote) are configured elsewhere

Open questions:
- Is logging synchronous or buffered?
	- Synchronous
- Should logs be persisted locally?
	- No
- Are logs user-visible or developer-only?
	- Only in development

---

#### 3.4.2 Time & Date Handling

Purpose:
Provide a single, controlled source of time-related behavior.

Responsibilities:
- Access to “current time”
- Date/time parsing and formatting
- Duration helpers
- Relative time calculations

Rules:
- Application code must not call `DateTime.now()` directly
- Time access must go through a shared abstraction
- All time values should be explicit and testable

Typical patterns:
- `TimeProvider` or similar abstraction
- Injectable clock for testing
- Explicit UTC handling

Constraints:
- Must be deterministic under test
- Must support serialization safely
- Must avoid implicit timezone behavior

Assumptions:
- Internal time representation is UTC
- Formatting is handled at presentation boundaries

Open questions:
- Should time be injectable at the provider level?
- Should historical data ever be reinterpreted under different timezones?
	- We should convert UTC times to reflect whatever time zone the user is in when viewing the data
- Should monotonic time be supported for duration measurement?
	- Yes

---

### 3.5 Summary Constraints

- `core/` must remain dependency-free from features
- Features must be isolated and self-contained
- Communication occurs through explicit contracts
- Utilities must be deterministic and reusable
- Architecture prioritizes clarity and explicitness over convenience 


---

---

<!-- FILE: 4. Domain Model.md -->

<a id="4-domain-model"></a>

## 4. Domain Model

### 4.1 Core Concepts

#### 4.1.1 Account

##### Overview
Represents a single logical user context within AshTrail. All data (sessions, log entries, preferences) is scoped to an account.

##### Responsibilities
- Owns all sessions and log entries
- Defines isolation boundary between multiple users on the same device
- Acts as the root entity for sync and persistence

##### Data Structures
| Field          | Type     | Constraints                          |
| -------------- | -------- | ------------------------------------ |
| id             | String   | Required, locally unique             |
| remoteId       | String?  | Optional, assigned after remote sync |
| email          | String   | Required                             |
| displayName    | String   | Required                             |
| firstName      | String?  | Optional                             |
| lastName       | String?  | Optional                             |
| createdAt      | DateTime | Required, immutable                  |
| lastModifiedAt | DateTime | Required                             |

##### State & Flow
- Created locally
- May exist indefinitely without a remote ID
- Becomes sync-eligible once remote ID is assigned

##### Edge Cases & Failure Modes
- Account deletion must cascade to sessions and log entries
- Switching accounts must store still logged in data since swapping will not sign out the other user

##### Future Extensions
- Account-level preferences
- Account sharing or export/import

---
#### 4.1.2 Log Entry

##### Overview
Atomic record representing a single logged event.

##### Responsibilities
- Capture user-entered or system-generated data
- Provide normalized, analyzable records

##### Data Structures
| Field          | Type     | Constraints |
| -------------- | -------- | ----------- |
| id             | String   | Required    |
| accountId      | String   | Required    |
| type           | Enum     | Required    |
| duration       | Number   | Required    |
| reason         | Enum     | Optional    |
| moodRating     | Number   | Optional    |
| physicalRating | Number   | Optional    |
| eventTime      | DateTime | Required    |
| createdAt      | DateTime | Required    |
| syncState      | Enum     | Required    |

##### State & Flow
- Created locally
- Stored offline-first
- Marked synced after successful remote persistence

##### Edge Cases & Failure Modes
- Duplicate entries due to retry logic
- Invalid values bypassing UI validation

##### Future Extensions
- Tagging
- Annotations or notes

---
##### 4.1.3.1 Log Entry Variants

###### 4.1.3.1.1 Manual Entry

##### Overview
Represents a user-entered log with explicitly provided values.

##### Responsibilities
- Capture direct user input
- Preserve exact entered value

##### Additional Constraints
- value must be user-supplied
- eventTime may differ from createdAt

---
### 4.2 Identifiers

#### 4.2.1 Local IDs

##### Overview
Identifiers generated locally for offline-first operation.

##### Characteristics
- Unique per device
- Stable across app restarts
- Used as primary keys locally

##### Assumptions
- Collision risk is negligible

---
#### 4.2.2 Remote IDs

##### Overview
Identifiers assigned by the remote backend after sync.

##### Characteristics
- Optional until sync completes
- Mapped to local IDs
- Used for conflict resolution

##### Edge Cases
- Partial syncs where remote ID is missing

---
### 4.3 Time Semantics

#### 4.3.1 Event Time vs Sync Time

##### Overview
Distinguishes when something happened from when it was synchronized.

##### Definitions
- **Event Time**: When the user action occurred
- **Sync Time**: When the record was persisted remotely

##### Constraints
- Event time is immutable
- Sync time may change across retries

##### Assumptions
- All times stored in UTC

---
### 4.4 Units & Normalization

#### 4.4.1 Measurement Units

##### Overview
Defines the units used for log entry values and how they are normalized.

##### Supported Units
- Duration (seconds)
- Count-based units
- Other domain-specific units as defined in code

##### Normalization Rules
- Values stored in a canonical base unit
- Display units handled at presentation layer

##### Open Questions
- Are mixed units allowed per log type?
	- No

---
### 4.5 Constraints

#### 4.5.1 Required Fields

- accountId
- duration
- unit
- eventTime

Missing required fields must block persistence.

---
#### 4.5.2 Value Bounds

##### Rules
- Values must be non-negative
- Upper bounds enforced per log type

##### Failure Modes
- Invalid bounds causing rejected entries
- UI and domain validation divergence

##### Future Extensions
- Configurable bounds per account
---

<!-- FILE: 5. Logging System.md -->

<a id="5-logging-system"></a>

## 5. Logging System

### 5.1 Overview

#### 5.1.1 Why Logging Is Central

**Logging is the core function of AshTrail.**  
All analytics, insights, trends, and behavioral summaries are derived from log entries.

The system is designed to:
- Capture user activity with minimal friction
- Preserve data offline-first
- Support multi-account separation
- Enable deterministic replay and analysis over time

There is no “secondary” data source for behavior—**logs are the source of truth**.

---

### 5.2 Log Entry Lifecycle

This section describes how a log entry is created, stored, validated, and eventually synchronized.

#### 5.2.1 Creation

Log entries can be created from two primary sources.

##### 5.2.1.1 UI Initiated

Logs created directly through user interaction:
- Time-of entry forms
	- Includes all input options and a long press button that records the event duration and acts as the submission once the button is released

Characteristics:
- Always tied to a visible user action
- Must pass full client-side validation
- Timestamp assigned at creation time via centralized time abstraction
- Associated with the currently active account and session context

---
#### 5.2.2 Local Persistence

All log entries are persisted locally immediately upon creation.

Local storage characteristics:
- Offline-first
- Durable across app restarts
- Account-scoped
- Append-only by default

Local persistence occurs:
- Before any remote sync attempt
- Regardless of network availability

**Assumption**
- Local persistence uses a structured, queryable store (not raw JSON blobs)

---
#### 5.2.3 Sync Eligibility

A log entry becomes eligible for sync when:
- It passes validation
- It is not marked as deleted
- It has not already been successfully synced
- A remote backend is configured and enabled

Sync metadata may include:
- Sync status (pending / synced / failed)
- Last sync attempt timestamp
- Remote identifier (if synced)

**Assumption**
- Sync eligibility is evaluated lazily, not continuously

**Open Questions**
- Is sync manual, automatic, or hybrid?
- Are retries exponential or fixed-interval?

---
#### 5.2.4 Remote Persistence

When eligible, logs may be written to a remote backend.

Remote persistence characteristics:
- Idempotent writes
- Account-isolated
- Conflict-safe (single-writer assumption)

Remote storage is treated as:
- A backup
- A cross-device sync layer
- A future analytics source

**Assumption**
- Remote persistence failures never block local usage

---
### 5.3 Input Types

AshTrail supports a constrained set of log input types to preserve consistency and enable analysis.

#### 5.3.1 Numeric Inputs

Examples:
- Counts
- Quantities
- Scalar measurements

Rules:
- Must be finite numbers
- No implicit unit conversion
- Stored as raw numeric values

Constraints:
- Upper and lower bounds may apply per field

---
#### 5.3.2 Duration Inputs

Examples:
- Time durations

Rules:
- Stored as normalized durations (not timestamps)
- Must be non-negative
- Precision defined centrally

**Assumption**
- Duration is stored independently of start/end timestamps

---
#### 5.3.3 Boolean Flags

Examples:
- Yes / No markers
- Binary conditions

Rules:
- Explicit true or false
- No tri-state values
- Defaults must be defined

---
### 5.4 Validation Rules

#### 5.4.1 Client-Side Validation

All validation occurs client-side before persistence.

Validation includes:
- Required field presence
- Type correctness
- Value bounds
- Logical consistency between fields

Failure behavior:
- Entry is rejected
- User is notified (UI-initiated only)
- No partial persistence

**Assumption**
- Server-side validation mirrors client rules but does not extend them

**Open Question**
- Are historical logs ever revalidated when rules change?
	- No

---
### 5.5 Editing & Deletion

Log entries are mutable only under strict rules.

#### 5.5.1 Soft vs Hard Deletes

**Soft Delete**
- Entry is marked as deleted
- Remains in local storage
- Excluded from analytics and sync
- Can be restored

**Hard Delete**
- Entry is permanently removed
- Irreversible
- Used sparingly (e.g., data repair)

**Assumption**
- UI exposes soft delete only
- Hard delete is reserved for internal tools or migrations

---
### 5.6 Assumptions

#### 5.6.1 Single-Writer Model

AshTrail assumes:
- One active writer per account at any time
- No concurrent edits across devices
- Conflicts are avoided by design, not resolved after the fact

This simplifies:
- Sync logic
- Conflict handling
- Data consistency guarantees

**Open Question**
- Will future versions support concurrent multi-device editing?
	- No
---

<!-- FILE: 6. State Management.md -->

<a id="6-state-management"></a>

## 6. State Management

### Overview
State management in AshTrail coordinates application lifecycle, account context, logging workflows, synchronization, and error handling. It is designed to support:
- Multi-account usage
- Offline-first operation
- Predictable, recoverable state transitions
- Explicit separation between transient UI state and persisted domain state

State is primarily managed using Riverpod providers, with clear ownership boundaries between global, account-scoped, and feature-specific state.

---

### Responsibilities
- Initialize application dependencies and determine startup flow
- Track and switch active accounts
- Manage in-progress and persisted log entries
- Coordinate local vs remote (Firestore) synchronization
- Surface recoverable and fatal errors consistently

---

### 6.1 Global State

#### 6.1.1 App Initialization State

#### Overview
Represents the app-wide startup lifecycle before user interaction is possible.

#### Responsibilities
- Load core services (storage, sync engine, config)
- Determine authentication and account availability
- Gate navigation until initialization completes

#### Data Structures
| Field | Type | Description |
|-----|-----|------------|
| `status` | enum | `uninitialized`, `initializing`, `ready`, `failed` |
| `error` | Error? | Initialization failure details |

#### State & Flow
1. App launch triggers `initializing`
2. Core dependencies are constructed
3. Local persistence is checked
4. App transitions to `ready` or `failed`

#### Edge Cases & Failure Modes
- Corrupted local storage
- Missing required configuration
- Partial initialization success

#### Assumptions
- Initialization runs exactly once per app launch
- No user interaction before `ready`

#### Open Questions
- Should initialization be retryable without app restart?
	- Yes, if we retry transition from the loading screen to a message letting the user know and if it fails again says it’s having issues right now check for updates or try again later

---

### 6.2 Account State

#### 6.2.1 Active Account Selection

#### Overview
Tracks which account is currently active and scopes all logging and analytics operations.

#### Responsibilities
- Store active account ID
- Trigger downstream state resets on account switch

#### Data Structures
| Field               | Type    | Description                |
| ------------------- | ------- | -------------------------- |
| `activeAccountId`   | string  | Currently selected account |
| `availableAccounts` | List<?> | Locally known accounts     |


#### State & Flow
- On app start, last-used account is restored if available
- Changing the active account invalidates:
  - Logging draft state
  - Account-scoped caches
  - Sync queues

#### Edge Cases & Failure Modes
- Active account deleted locally
- Account exists locally but not remotely

#### Assumptions
- Exactly one active account at a time

---

### 6.3 Logging State

#### 6.3.1 Draft State

#### Overview
Represents in-progress, unsaved log entries.

#### Responsibilities
- Hold temporary user input
- Support partial completion and cancellation
- Validate inputs before persistence

#### Data Structures
| Field | Type | Description |
|-----|-----|------------|
| `draftId` | string | Ephemeral identifier |
| `fields` | map | Input values by field |
| `isValid` | bool | Validation result |

#### State & Flow
- Draft is created on log start
- Updated on each input change
- Discarded on cancel or successful save

#### Edge Cases & Failure Modes
- App backgrounded mid-draft
- Account switch with active draft

#### Assumptions
- Draft state is never persisted automatically

---

### 6.3.2 Persisted State

#### Overview
Represents saved log entries stored locally and optionally synced remotely.

#### Responsibilities
- Provide immutable access to saved logs
- Serve as the source of truth for analytics

#### Data Structures
| Field | Type | Description |
|-----|-----|------------|
| `logId` | string | Stable identifier |
| `timestamp` | DateTime | Log time |
| `data` | map | Structured log payload |
| `syncStatus` | enum | `local`, `pending`, `synced`, `conflict` |

#### State & Flow
- Draft transitions to persisted on save
- Persisted logs enter sync pipeline

---

### 6.4 Sync State

#### 6.4.1 Pending Changes

#### Overview
Tracks local changes awaiting remote synchronization.

#### Responsibilities
- Queue unsynced operations
- Retry failed sync attempts

#### Data Structures
| Field | Type | Description |
|-----|-----|------------|
| `pendingLogs` | List<logId> | Logs awaiting sync |
| `lastAttempt` | DateTime? | Last sync attempt |

#### State & Flow
- New persisted logs are marked `pending`
- Sync engine processes queue when online

#### Edge Cases & Failure Modes
- Large offline backlog
- Repeated transient network failures

---

### 6.4.2 Conflict State

#### Overview
Represents detected divergence between local and remote data.

#### Responsibilities
- Surface conflicts to resolution logic
- Prevent silent overwrites

#### Data Structures
| Field | Type | Description |
|-----|-----|------------|
| `conflictingLogId` | string | Affected log |
| `localVersion` | LogEntry | Local data |
| `remoteVersion` | LogEntry | Remote data |

#### Assumptions
- Conflicts are rare and explicit

#### Open Questions
- Will conflict resolution be automatic or user-driven?

---

### 6.5 Error State

#### 6.5.1 Recoverable Errors

#### Overview
Errors that allow continued app operation.

#### Responsibilities
- Inform the user
- Allow retry or graceful degradation

#### Examples
- Network unavailable
- Temporary sync failure
- Validation errors

---

### 6.5.2 Fatal Errors

#### Overview
Errors that prevent safe continuation.

#### Responsibilities
- Halt affected flows
- Provide diagnostic context

#### Examples
- Unrecoverable data corruption
- Initialization failure

#### Assumptions
- Fatal errors require app restart or reinstall

---

### Future Extensions
- Time-travel debugging for state transitions
- Per-account error isolation
- Background sync progress state
- Formal state machine definitions for critical flows

---

---

<!-- FILE: 7. Data Persistence.md -->

<a id="7-data-persistence"></a>

## 7. Data Persistence
### 7.1 Local Database (Hive)
#### 7.1.1 Overview
The local database is the system of record for AshTrail during normal operation.
- Enables offline-first behavior
- Guarantees durability of user-entered data
- Acts as the staging layer for sync to Firestore
- Must always be writable, regardless of network state

Hive is used due to:
- Low overhead
- Strong Flutter integration
- Predictable key–value semantics
- No background services or migrations required 

---
#### 7.1.1 Collections
Hive boxes are treated conceptually as collections.
##### 7.1.1.1 Log Records
Stores all log entries created by the user.

**Responsibilities**
- Persist every log entry immediately on creation
- Maintain authoritative local history
- Track sync state per record

**Fields**

| Field            | Type                 | Constraints                    |
| ---------------- | -------------------- | ------------------------------ |
| id               | String               | Unique, immutable              |
| accountId        | String               | Required                       |
| timestamp        | DateTime             | UTC, immutable                 |
| type             | enum                 | Must match supported log types |
| payload          | Map<String, dynamic> | Type-specific                  |
| createdAt        | DateTime             | UTC                            |
| updatedAt        | DateTime             | UTC                            |
| syncStatus       | enum                 | `pending`, `synced`, `error`   |
| lastSyncAttempt  | DateTime?            | Nullable                       |

**Assumptions**
- IDs are generated locally and reused for Firestore documents
- Timestamps are never mutated after creation 

---
##### 7.1.1.2 Accounts
Stores local account metadata.

**Responsibilities**
- Support multi-account switching
- Cache minimal account identity and state
- Avoid remote dependency for account selection

**Fields**

| Field        | Type     | Constraints      |
| ------------ | -------- | ---------------- |
| accountId    | String   | Primary key      |
| displayName  | String   | Required         |
| createdAt    | DateTime | UTC              |
| isActive     | bool     | Exactly one true |
**Assumptions**
- Authentication is handled elsewhere
- Accounts may exist locally before remote sync

---
#### 7.1.2 Indexing Strategy

Hive does not provide secondary indexes. Indexing is handled manually.

**Strategies**
- Primary key lookup by `id`
- In-memory filtered views via Riverpod
- Time-based queries performed by sorting cached lists  

**Constraints**
- No compound queries at the persistence layer
- All derived views are computed, not stored  

**Open Questions**
- Is Hive sufficient long-term for large datasets?
- Should log partitioning be introduced by date?  

---
### 7.2 Remote Database (Firestore)
#### 7.2.1 Overview
Firestore serves as:
- Cross-device sync target
- Backup and recovery layer
- Optional analytics source

Firestore is not considered authoritative during active sessions.

---
#### 7.2.1 Collection Structure
##### 7.2.1.1 Per-Account Namespacing
Data is namespaced per account to avoid cross-contamination.

**Structure**

accounts/{accountId}
└── logs/{logId}

**Rules**
- No global log collections
- Account ID is always embedded in the path
- Security rules enforce account isolation
---
#### 7.2.2 Document Shapes

Firestore documents mirror Hive records closely.

**Log Document Fields**

| Field       | Type      | Notes            |
| ----------- | --------- | ---------------- |
| id          | String    | Matches local ID |
| timestamp   | Timestamp | UTC              |
| type        | String    | Enum string      |
| payload     | Map       | Serialized       |
| createdAt   | Timestamp |                  |
| updatedAt   | Timestamp |                  |

**Constraints**
- No server-generated IDs
- No server timestamps required for correctness

**Assumptions**
- Client clocks are reasonably accurate
- Firestore is used in a single-region configuration

---

### 7.3 Sync Strategy
#### 7.3.1 Push Model
Local → Remote sync is the primary direction.

**Flow**
1. Observe locally `pending` records
2. Serialize and write to Firestore
3. On success:
   - Mark record as `synced`
   - Update `lastSyncAttempt`
1. On failure:
   - Mark record as `error`

**Rules**
- Never block UI on sync
- Never delete local data after sync 

---
#### 7.3.2 Pull Model
Remote → Local sync is secondary and explicit.

**Use Cases**
- New device
- Manual refresh
- Account recovery  

**Flow**
1. Fetch all remote logs for account
2. Compare by `id`
3. Insert missing local records only

**Constraints**
- No overwrite of existing local records
- No bidirectional merging  

**Assumptions**

- Local data is always newer or authoritative

  

---
#### 7.3.3 Conflict Resolution

Conflicts are resolved deterministically

**Rules**
- Local wins over remote
- Duplicate IDs are ignored
- No field-level merges

**Rationale**
- Logs are append-only
- Mutations are rare and controlled
- Simplicity over eventual consistency

**Open Questions**
- Should edits to existing logs be supported later?
- Is a tombstone mechanism required? 

---
### 7.4 Failure Modes
#### 7.4.1 Network Loss

**Behavior**
- All writes remain local
- Sync retries are deferred
- UI reflects unsynced state only via metadata

**Guarantees**
- No data loss
- No user action required to recover

---
#### 7.4.2 Partial Writes

**Scenarios**
- Firestore write succeeds but local update fails
- Local update succeeds but Firestore write fails
  
**Handling**
- Local state is always treated as source of truth
- Firestore inconsistencies are resolved on next push
- Duplicate writes are idempotent by ID  

**Assumptions**
- Firestore writes are atomic per document
- Network failures are transient
  
---
### 7.5 Future Extensions

**Clearly Out of Scope**
- Real-time listeners
- Multi-user collaboration
- Server-side aggregation

**Possible Extensions**
- Incremental pull with checkpoints
- Soft-delete and edit support
- Background sync with OS scheduling

---

---

<!-- FILE: 8. Authentication & Accounts.md -->

<a id="8-authentication-&-accounts"></a>

## 8. Authentication & Accounts

### 8.1 Overview

This section documents how authentication and account identity are handled in AshTrail, including login, logout, account switching, and the distinction between anonymous and authenticated usage.

Authentication exists to:
- Associate log data with a persistent identity
- Support multi-account usage on a single device
- Enable future sync and cross-device continuity
- Preserve offline-first behavior without blocking usage

AshTrail is designed to function without authentication, with auth treated as an optional capability layer rather than a hard requirement.

---

### 8.2 Responsibilities

Authentication and account handling are responsible for:
- Managing user authentication state (authenticated vs anonymous)
- Tracking the currently active account
- Enforcing session reset rules on account changes
- Determining data ownership and visibility
- Handling transitions between anonymous and authenticated states
- Preventing cross-account data leakage

Out of scope:
- Password management UI
- Advanced security features (e.g., MFA)
- Server-side auth enforcement details (unless explicitly implemented)

---

### 8.3 Auth Flow

#### 8.3.1 Login

**Purpose**
- Establish an authenticated identity
- Bind the current session to an account

**High-level flow**
1. User initiates login action
2. Authentication provider returns a user identity
3. App resolves or creates a corresponding local Account record
4. Active account state is updated
5. Session-scoped state is reset according to rules

**Key behaviors**
- Login does not implicitly delete local data
- Login may trigger data migration from anonymous state (see 8.5)
- Login must be safe to perform while offline (graceful failure)

**Assumptions**
- Authentication provider SDK handles credential validation
- A unique, stable user identifier is available post-login

**Open questions**
- Is login allowed while offline using cached credentials?
- Are multiple auth providers supported or planned?

---

#### 8.3.2 Logout

**Purpose**
- Remove authenticated context
- Return the app to an unauthenticated (anonymous) state

**High-level flow**
1. User initiates logout
2. Authentication tokens are cleared
3. Active account is unset or replaced with an anonymous account
4. Session-scoped state is reset

**Key behaviors**
- Local data is not deleted on logout
- Logout must not block access to existing local logs
- UI should immediately reflect unauthenticated state

**Assumptions**
- Anonymous usage is always permitted
- Logout does not require network access

---

### 8.4 Account Switching

Account switching allows multiple logical accounts to exist on a single device, regardless of authentication state.

#### 8.4.1 Session Reset Rules

When the active account changes (login, logout, or manual switch):

**Must reset**
- In-memory session state
- Active filters and views
- Draft or unsaved log entries
- Any account-scoped caches

**Must not reset**
- Persistent local storage
- Other accounts’ data
- Global app configuration unrelated to account identity

**Invariant**
- At no point should data from one account be visible under another account context

**Assumptions**
- Each log record is explicitly associated with an account ID
- State management enforces account boundaries

---

### 8.5 Anonymous vs Authenticated

AshTrail distinguishes between:
- **Anonymous accounts**: Local-only, no external identity
- **Authenticated accounts**: Backed by an auth provider identity

Anonymous usage is a first-class mode, not a temporary state.

#### 8.5.1 Data Migration Rules

**Scenario: Anonymous → Authenticated**
- Anonymous data may optionally be migrated to the authenticated account
- Migration must be explicit and deterministic
- No automatic merging without clear ownership rules

**Scenario: Authenticated → Anonymous**
- Authenticated data remains associated with its account
- Anonymous account starts with a clean logical state

**Constraints**
- Migration must be idempotent
- Partial migration must not corrupt source or destination data

**Open questions**
- Is migration user-controlled or automatic?
- Are conflicts possible if authenticated account already has data?
- Is rollback supported if migration fails?

---

### 8.6 Security Assumptions

#### 8.6.1 Trust Model

AshTrail operates under the following trust assumptions:

- The client device is trusted
- Local storage is not encrypted beyond platform defaults
- Authentication providers are trusted to validate identity
- No hostile multi-user device scenarios are assumed

**Implications**
- App is not hardened against a malicious local user
- Data separation is logical, not cryptographic
- Security is focused on correctness, not adversarial resistance

**Non-goals**
- Preventing rooted/jailbroken device access
- Protecting against local filesystem inspection
- Enterprise-grade threat models

---

### 8.7 Edge Cases & Failure Modes

- Login succeeds but account resolution fails
- Logout during an active log entry
- App restart mid-account switch
- Migration interrupted by app termination
- Auth provider returns inconsistent user identifiers

**Expected handling**
- Fail safe: preserve data, reset session, require user re-entry
- Never delete data automatically
- Prefer explicit recovery paths over silent fixes

---

### 8.8 Future Extensions

Potential future additions (not currently implemented):

- Cross-device sync enforcement rules
- Account-level encryption keys
- Multiple authenticated accounts per provider
- Role-based access or shared accounts
- Explicit migration UI with preview and rollback

All future extensions must preserve:
- Offline-first usability
- Clear account boundaries
- Non-destructive behavior by default

---

---

<!-- FILE: 9. UI Architecture.md -->

<a id="9-ui-architecture"></a>

## 9. UI Architecture

### Overview
The UI Architecture defines how screens, navigation, widgets, and forms are structured and composed in AshTrail.  
Its primary goals are:

- Predictable navigation across core workflows
- Clear separation between UI, state, and domain logic
- Reusable, testable widgets
- Accessibility and platform-consistent behavior

This layer consumes state from Riverpod providers and emits user intent events. It must not contain business logic.

---

### Responsibilities
- Define navigation structure and routes
- Render screens based on application and account state
- Collect user input and surface validation feedback
- Provide reusable UI components
- Ensure baseline accessibility support

---

### 9.1 Navigation

### Overview
Navigation coordinates movement between high-level screens such as logging, history, and analytics.  
Navigation must be state-aware (e.g., active account, initialization complete).

---

### Responsibilities
- Declare routes and route names
- Control screen transitions
- Prevent navigation into invalid app states

---

### 9.1.1 Route Definitions

#### Data Structures
Routes are defined as named paths mapped to screen widgets.

| Field | Type | Description |
|-----|-----|------------|
| routeName | string | Unique route identifier |
| builder | WidgetBuilder | Screen constructor |
| requiresAccount | bool | Whether an active account is required |

#### State & Flow
- App startup resolves initialization state
- If no account is active, navigation is restricted
- Route changes are triggered by user actions or state changes

#### Assumptions
- Routing is centralized (not defined per-feature)
- Deep linking is not currently required

#### Open Questions
- Is declarative routing (e.g., Router API) planned?
- Should routes encode account IDs explicitly?

---

### 9.2 Screens

### Overview
Screens represent full-page UI surfaces.  
Each screen:
- Subscribes to relevant providers
- Delegates logic to controllers or services
- Renders composed widgets

---

### 9.2.1 Logging Screen

#### Responsibilities
- Capture new log entries
- Display current session context
- Submit validated log data

#### State & Flow
1. User selects log type
2. Input widgets update local form state
3. Validation runs on submit
4. Valid entries are persisted via logging controller
5. UI resets or advances based on result

#### Edge Cases
- Submission attempted with no active account
- Partial input for multi-field log types
- Rapid repeated submissions

---

### 9.2.2 History View

#### Responsibilities
- Display persisted log entries
- Support filtering and grouping
- Reflect account-scoped data

#### State & Flow
- Subscribes to log history provider
- Reacts to account switch events
- Rebuilds on data sync or local mutation

#### Edge Cases
- Empty history state
- Large datasets impacting scroll performance
- Logs created offline then synced

---

### 9.2.3 Analytics View

#### Responsibilities
- Visualize aggregated log data
- React to time range and filter changes
- Display derived metrics only (no raw mutation)

#### State & Flow
- Reads pre-aggregated analytics state
- Triggers recomputation via state changes
- Renders charts and summaries

#### Assumptions
- Analytics are read-only from the UI layer
- Heavy computation is not performed in widgets

---

### 9.3 Widgets

### Overview
Widgets are composable UI building blocks used across screens.

---

### 9.3.1 Reusable Components

#### Examples
- Labeled input rows
- Primary / secondary buttons
- Section headers
- Empty-state placeholders

#### Constraints
- Widgets must be stateless where possible
- Stateful widgets must not own business logic
- Styling is centralized via theme definitions

---

### 9.4 Forms

### Overview
Forms handle structured user input and validation feedback.

---

### 9.4.1 Input Handling

#### Responsibilities
- Maintain transient form state
- Normalize user input
- Emit submission intent

#### State & Flow
- Local form state tracks field values
- On change: update state only
- On submit: trigger validation pipeline

---

### 9.4.2 Validation Feedback

#### Responsibilities
- Surface field-level errors
- Prevent invalid submission
- Display global submission failures

#### Validation Types
- Required fields
- Type constraints (number, duration)
- Cross-field dependencies

#### Edge Cases
- Validation rules changing between app versions
- Legacy logs not matching new constraints

---

### 9.5 Accessibility Considerations

### Overview
Accessibility ensures the app remains usable across devices and user settings.

---

### 9.5.1 Text Scaling

#### Responsibilities
- Respect system text scale factor
- Avoid clipped or overlapping text
- Maintain readable layouts at large sizes

#### Constraints
- No fixed-height text containers
- Layouts must reflow vertically

#### Open Questions
- Is screen reader (TalkBack / VoiceOver) support explicitly targeted?
- Are color-contrast audits planned?

---

### Future Extensions
- Declarative navigation with guarded routes
- Deep linking support
- Keyboard navigation for tablets and desktop
- Full screen reader semantics annotations

---

---

<!-- FILE: 10. Analytics & Aggregation.md -->

<a id="10-analytics-&-aggregation"></a>

## 10. Analytics & Aggregation

### 10.1 Overview

The Analytics & Aggregation layer is responsible for transforming raw log entries into summarized, time-based insights that can be rendered efficiently in the UI.

This layer exists to:
- Enable meaningful interpretation of historical log data
- Support trend visualization over varying time windows
- Avoid storing redundant pre-aggregated data
- Keep analytics deterministic, reproducible, and offline-capable

All aggregation is derived from persisted log records and computed on demand.

---

### 10.2 Responsibilities

- Aggregate raw log entries into time-bucketed summaries
- Support multiple temporal windows (daily, rolling)
- Provide datasets suitable for charting and tabular display
- Ensure computations are scoped to the active account
- Enforce performance safeguards for large datasets
- Avoid mutating or enriching source log records

Out of scope:
- Predictive analytics
- Cross-account aggregation
- Server-side or cloud-based computation

---

### 10.3 Aggregation Goals

#### 10.3.1 Trend Analysis

Primary analytical objective:
- Identify behavioral patterns over time

Supported trend use cases:
- Frequency of log events over time
- Duration totals per time window
- Changes in usage intensity
- Visual detection of increases, decreases, or plateaus

Constraints:
- Trends must be derived strictly from stored log data
- No heuristic or inferred data is introduced
- Results must be explainable via underlying logs

---

### 10.4 Data Windows

Aggregation supports multiple temporal perspectives, each with distinct semantics.

#### 10.4.1 Daily

Definition:
- Aggregation grouped by calendar day

Characteristics:
- Fixed, non-overlapping buckets
- Day boundaries determined by normalized timestamp logic (see Time utilities)
- Suitable for:
  - Daily totals
  - Calendar-based charts
  - Long-term history views

Constraints:
- Requires consistent timezone handling
- Partial days may occur at dataset boundaries

#### 10.4.2 Rolling

Definition:
- Aggregation over a sliding time window relative to a reference point (usually “now”)

Examples:
- Last 7 days
- Last 30 days
- Last N hours

Characteristics:
- Overlapping windows
- Continuously shifting as time advances
- Suitable for:
  - Short-term behavior analysis
  - Trend smoothing
  - Recent usage emphasis

Constraints:
- Requires precise duration arithmetic
- Sensitive to timestamp accuracy and clock drift

---

### 10.5 Computation Location

#### 10.5.1 Client-Side Aggregation

All aggregation is performed locally on the client.

Rationale:
- Offline-first architecture
- Avoids backend dependency
- Guarantees user data locality
- Simplifies synchronization model

Implementation characteristics:
- Operates on in-memory collections loaded from local persistence
- Triggered by:
  - View initialization
  - Data window changes
  - New log insertions
- Results are ephemeral and not persisted

Constraints:
- Must be performant on mid-range mobile hardware
- Must avoid blocking the UI thread
- Should favor incremental or cached computation where feasible

---

### 10.6 Performance Constraints

#### 10.6.1 Large Datasets

Potential issues:
- Long-running aggregation on thousands of log entries
- Excessive memory allocation during grouping
- Repeated recomputation on minor UI changes

Mitigations:
- Limit aggregation scope to active account only
- Apply time-window filtering before grouping
- Reuse intermediate results when possible
- Defer heavy computation off the main UI thread
- Impose practical limits on historical depth rendered at once

Non-goals:
- Real-time streaming analytics
- Sub-second recomputation guarantees for arbitrarily large datasets

---

### 10.7 Data Structures

Aggregations operate on existing log entry structures.

Derived (non-persisted) structures may include:
- Time bucket key (date or window identifier)
- Aggregated count
- Aggregated duration totals
- Min/max timestamps within bucket

Constraints:
- Derived structures must be immutable once produced
- No derived structure is written back to persistence

---

### 10.8 State & Flow

High-level flow:
1. Load raw log entries for active account
2. Apply time-window filter
3. Group entries by aggregation window
4. Reduce groups into summary objects
5. Expose summaries to UI for rendering

Triggers:
- Account switch
- Data window change
- New log entry creation
- App initialization

---

### 10.9 Edge Cases & Failure Modes

- Empty datasets
- Single-entry datasets
- Logs spanning timezone changes
- Logs with identical timestamps
- Extremely dense logging periods
- Device clock changes affecting rolling windows

Expected behavior:
- Graceful empty-state handling
- No crashes due to malformed or unexpected data
- Deterministic results given the same input set

---

### 10.10 Assumptions

- Log timestamps are normalized consistently at write time
- All analytics are scoped to one active account
- Client devices have sufficient resources for local aggregation
- Aggregation does not require cryptographic or audit-grade accuracy

---

### 10.11 Open Questions

- Should aggregation results be cached across sessions?
- Is there a maximum historical range enforced for analytics views?
- Should rolling windows be anchored to “now” or to last log timestamp?
- Do analytics need to remain stable across timezone changes?

---

### 10.12 Future Extensions

Clearly non-implemented possibilities:
- Precomputed summaries for very large histories
- Background aggregation jobs
- Exportable analytics datasets
- Custom user-defined aggregation windows
- Comparative analytics across accounts (if ever allowed)

These are explicitly out of scope for the current implementation.

---

---

<!-- FILE: 11. Error Handling & Observability.md -->

<a id="11-error-handling-&-observability"></a>

## 11. Error Handling & Observability

### 11.1 Overview

This section defines how AshTrail detects, classifies, records, and responds to errors at runtime.  
The goal is to:

- Prevent silent failures
- Preserve user trust and data integrity
- Enable debugging without external observability infrastructure
- Support future expansion into analytics or remote telemetry

AshTrail is intentionally offline-first and single-user per account; error handling favors **local resilience and transparency** over centralized reporting.

---

### 11.2 Responsibilities

The error handling and observability layer is responsible for:

- Classifying errors into actionable categories
- Ensuring failures are logged consistently
- Providing safe recovery paths without data loss
- Avoiding crashes caused by non-fatal issues
- Preserving enough context to debug issues after the fact

Non-responsibilities:

- No real-time alerting
- No crash reporting to third-party services
- No automatic remote log uploads

---

### 11.3 Error Classification

Errors are grouped by **source and impact**, not by exception type.

### 11.3.1 User Errors

Errors caused by invalid user actions or inputs.

**Characteristics**
- Predictable
- Recoverable
- Do not indicate a bug

**Examples**
- Submitting a log with missing required fields
- Selecting an account that no longer exists
- Entering invalid numeric values (e.g., negative duration)

**Handling Rules**
- Do not crash
- Display user-facing feedback
- Do not log as system failures
- May be logged as debug events (optional)

**Visibility**
- UI-level validation messages
- Snackbars / inline error text

---

### 11.3.2 System Errors

Errors caused by internal failures or unexpected state.

**Characteristics**
- Unpredictable
- May indicate bugs or data corruption
- Require investigation

**Examples**
- Hive read/write failure
- Deserialization errors
- State mismatch between providers
- Unhandled exceptions in async flows

**Handling Rules**
- Log immediately
- Preserve context (stack trace, state snapshot)
- Attempt graceful degradation when possible
- Fail fast only if data integrity is at risk

**Visibility**
- Not always visible to the user
- May surface as generic error messages

---

### 11.4 Logging Strategy

AshTrail uses **structured local logging** for observability.  
Logs are not intended for user consumption but for debugging and auditability.

### 11.4.1 Debug Logs

Used during development and troubleshooting.

**Purpose**
- Trace state transitions
- Diagnose unexpected behavior
- Verify assumptions during feature work

**Characteristics**
- Verbose
- Not persisted long-term (implementation-dependent)
- Safe to disable in production builds

**Typical Contents**
- Provider lifecycle events
- State changes
- Function entry/exit
- Non-fatal exceptions

**Constraints**
- Must not include sensitive user data
- Must not impact performance in release mode

---

### 11.4.2 Audit Logs

Used to record **meaningful system events**.

**Purpose**
- Track data mutations
- Reconstruct timelines
- Support future analytics

**Examples**
- Log entry created / updated / deleted
- Account switched
- Sync attempted or failed
- Recovery action triggered

**Characteristics**
- Structured
- Deterministic
- Persisted locally

**Relationship to Logging System**
- Audit logs may reuse the core logging infrastructure
- Distinct from user log entries (smoking/activity logs)

---

### 11.5 Recovery Paths

Recovery is preferred over failure whenever it does not compromise correctness.

### 11.5.1 Retry Logic

Retries are applied selectively and explicitly.

**Eligible Operations**
- Local persistence writes
- Background sync operations
- Non-idempotent operations only if safe

**Rules**
- Never infinite retries
- Use capped retry counts
- Prefer retry with delay over immediate retry
- Abort if state changes invalidate the operation

**Non-Goals**
- No global retry middleware
- No silent retries for user-triggered actions without feedback

---

### 11.6 State & Flow

High-level error flow:

1. Operation begins
2. Failure occurs
3. Error is classified
4. Appropriate log is recorded
5. Recovery attempted if applicable
6. User notified only if actionable

Error handling must not mutate state unless explicitly part of recovery logic.

---

### 11.7 Edge Cases & Failure Modes

- Corrupted local database
- Partial writes during app termination
- Provider initialization failures
- Version mismatch after app upgrade
- State deserialization errors after schema changes

Each must fail safely without cascading crashes.

---

### 11.8 Assumptions

- App runs without guaranteed network access
- Single active user per device at a time
- Logs are primarily developer-facing
- No legal or compliance audit requirements

---

### 11.9 Open Questions

- Should audit logs be queryable via UI?
- Should error events be surfaced in analytics views?
- Is a structured error model (ErrorCode enum) required?
- Should retry behavior be configurable per feature?

---

### 11.10 Future Extensions

Clearly out of scope for current implementation:

- Remote error reporting
- Crash analytics integration
- User-accessible diagnostics export
- Structured telemetry pipelines
- Background health checks

---

---

<!-- FILE: 12. Configuration & Environments.md -->

<a id="12-configuration-&-environments"></a>

## 12. Configuration & Environments

### Overview
This section defines how AshTrail differentiates behavior between development and production environments, how features are conditionally enabled or disabled, and how sensitive configuration (e.g., Firebase credentials) is managed. The goal is to ensure predictable builds, safe testing, and clear separation between non-production and production data.

---

### Responsibilities
- Provide deterministic environment-specific behavior.
- Prevent accidental use of production services during development.
- Enable or disable features without runtime ambiguity.
- Ensure secrets are not hard-coded or exposed in source control.

---

### 12.1 Build Flavors

#### Overview
Build flavors are used to produce environment-specific builds of the application. Each flavor controls configuration such as backend endpoints, Firebase projects, logging verbosity, and feature availability.

---

### Responsibilities
- Select the correct environment configuration at build time.
- Gate environment-specific services (e.g., Firestore collections).
- Enable stricter validation and observability in non-production builds.

---

### 12.1.1 Development

#### Overview
The development flavor is intended for local development, testing, and experimentation. It prioritizes debuggability and safety over performance or strict validation.

#### Characteristics
- Uses non-production Firebase project.
- Writes to development or test Firestore collections.
- Debug logging enabled.
- Feature flags default to permissive or experimental values.

#### Constraints
- Must never write to production data stores.
- Must clearly identify itself as non-production (e.g., app label, logs).

---

### 12.1.2 Production

#### Overview
The production flavor is intended for end users. It prioritizes stability, data integrity, and minimal observability overhead.

#### Characteristics
- Uses production Firebase project.
- Writes only to production Firestore collections.
- Debug logging disabled or heavily restricted.
- Feature flags default to stable, vetted values.

#### Constraints
- No development-only tools or mock data.
- Secrets must be resolved securely and correctly at build time.

---

### 12.2 Feature Flags

### Overview
Feature flags allow conditional inclusion or exclusion of functionality without branching runtime logic excessively. In AshTrail, feature flags are primarily compile-time–driven.

---

### Responsibilities
- Gate incomplete or experimental features.
- Allow environment-specific feature availability.
- Avoid runtime feature drift between sessions.

---

### 12.2.1 Compile-Time Flags

#### Overview
Compile-time flags are resolved during the build process and baked into the application binary.

#### Usage
- Enable or disable entire features or code paths.
- Select between alternative implementations.
- Reduce runtime conditional complexity.

#### Constraints
- Changes require a rebuild.
- Flags must be clearly documented and discoverable.

#### Assumptions
- Feature flags are defined in a central location.
- Flags are environment-aware (development vs production).

#### Open Questions
- Are flags managed via Dart `--dart-define` values or build flavor constants?
- Is there a formal naming convention for feature flags?

---

### 12.3 Secrets Management

### Overview
Secrets management covers how sensitive credentials and keys are stored, accessed, and protected across environments.

---

### Responsibilities
- Prevent secrets from being committed to source control.
- Ensure correct secrets are used per environment.
- Support local development without leaking production credentials.

---

### 12.3.1 Firebase Keys

#### Overview
Firebase keys and configuration values are required to initialize Firebase services such as Authentication and Firestore.

#### Handling
- Stored outside of source control.
- Environment-specific (development vs production).
- Injected at build time or via platform-specific configuration files.

#### Constraints
- Production Firebase keys must never be bundled with development builds.
- Keys must align with the selected build flavor.

#### Assumptions
- Firebase configuration files are excluded from version control.
- Separate Firebase projects exist for development and production.

#### Open Questions
- Are Firebase configs provided via platform files (`google-services.json`, `GoogleService-Info.plist`) or environment variables?
- Is there a documented rotation or revocation process for compromised keys?

---

### Edge Cases & Failure Modes
- Development build accidentally pointing to production Firebase project.
- Missing or misconfigured Firebase keys causing startup failure.
- Feature flag mismatch between documented and actual behavior.
- Build flavor not correctly propagated to runtime configuration.

---

### Future Extensions
- Runtime-configurable feature flags with remote config.
- Automated validation to prevent cross-environment misconfiguration.
- Centralized secrets management service integration.
- Build-time checks enforcing flavor/secret alignment.

---

---

<!-- FILE: 13. Testing Strategy.md -->

<a id="13-testing-strategy"></a>

## 13. Testing Strategy

### Overview
Defines how AshTrail is tested to ensure correctness, stability, and regressions are caught early.  
Testing prioritizes deterministic behavior, offline-first correctness, and multi-account safety.

---

### 13.1 Unit Tests

### Overview
Unit tests validate pure logic without Flutter widgets, platform services, or external I/O.  
They serve as the first line of defense against logic regressions.

### Responsibilities
- Verify domain rules and invariants
- Ensure state reducers and helpers behave deterministically
- Validate serialization and transformation logic

### 13.1.1 Domain Logic

#### Covered Areas
- Log entry creation and normalization
- Duration calculations
- Time utilities (relative time, formatting)
- Validation helpers (input bounds, required fields)
- Aggregation helpers (daily, rolling windows)

#### Data Structures Tested
| Component | Focus |
|---------|------|
| LogEntry | Field validity, defaults, serialization |
| Session | State transitions |
| Aggregates | Correct grouping and totals |

#### Constraints
- No use of `DateTime.now()` directly
- Time must be injected or mocked
- Tests must be deterministic and repeatable

#### Edge Cases & Failure Modes
- Zero-length durations
- Invalid timestamps
- Missing optional fields
- Large data sets causing overflow or precision issues

#### Assumptions
- Domain logic is fully decoupled from Flutter
- Pure Dart tests run quickly and frequently

#### Open Questions
- Is property-based testing desired for aggregates?
- Should fuzz testing be introduced for parsers?

---

### 13.2 Widget Tests

### Overview
Widget tests validate UI behavior in isolation without real network or storage.

### Responsibilities
- Verify widgets render expected states
- Validate user input handling
- Ensure visual feedback matches state

### 13.2.1 Form Validation

#### Covered Forms
- Log entry input
- Account creation / switching
- Filters and date selectors

#### Validation Scenarios
- Required fields missing
- Invalid numeric ranges
- Disabled submit on invalid state
- Error messages displayed correctly

#### State & Flow
1. Widget rendered with initial state
2. User input simulated
3. Validation triggered
4. UI reacts (error text, button state)

#### Edge Cases & Failure Modes
- Rapid input changes
- Form submission spam
- Keyboard dismissal mid-input

#### Assumptions
- Validation logic is centralized, not duplicated per widget

#### Open Questions
- Should golden tests be added for critical screens?

---

### 13.3 Integration Tests

### Overview
Integration tests validate end-to-end behavior across state, persistence, and sync layers.

### Responsibilities
- Ensure systems work together correctly
- Catch issues not visible in isolation

### 13.3.1 Sync Scenarios

#### Covered Scenarios
- Offline log creation → later sync
- Conflict resolution between local and remote data
- Account switching with pending sync
- Partial sync failures

#### State & Flow
1. App starts offline
2. User creates data
3. App transitions online
4. Sync engine runs
5. Remote and local states converge

#### Edge Cases & Failure Modes
- Network flapping during sync
- Duplicate uploads
- Corrupted local cache
- Auth token expiration mid-sync

#### Assumptions
- A mock or staging backend is available
- Sync logic is idempotent

#### Open Questions
- How are sync conflicts surfaced to the user?
- Should sync retries be time-based or event-based?

---

### 13.4 Manual Testing

### Overview
Manual testing complements automated tests for UX, rare edge cases, and exploratory scenarios.

### Responsibilities
- Validate real-device behavior
- Catch usability issues
- Verify platform-specific behavior

### 13.4.1 Edge Case Checklists

#### General
- App kill and resume during critical actions
- Background → foreground transitions
- Low battery / low memory conditions

#### Data
- Large historical datasets
- Rapid account switching
- Deleting accounts with existing logs

#### UI
- Small screen devices
- Accessibility font scaling
- Dark mode / light mode transitions

#### Sync
- Airplane mode toggling
- Login/logout during sync
- Corrupted or missing remote data

#### Assumptions
- Manual testing is performed before releases
- Issues found are converted into automated tests when possible

---

### Future Extensions
- Automated performance benchmarks
- Load testing for large datasets
- Chaos testing for sync reliability
- CI-enforced coverage thresholds

---

---

<!-- FILE: 14. Deployment & Distribution.md -->

<a id="14-deployment-&-distribution"></a>

## 14. Deployment & Distribution

### 14.1 Build Process

#### Overview
Defines how AshTrail is built locally and prepared for platform-specific distribution. This section exists to ensure builds are reproducible, debuggable, and aligned with environment constraints.

#### Responsibilities
- Produce deterministic builds for development and release
- Separate debug/dev artifacts from production artifacts
- Enforce environment-specific configuration boundaries
- Ensure build outputs match platform store requirements

#### Data Structures
_Not applicable._  
Build configuration is defined via Flutter tooling and environment flags rather than runtime data structures.

#### State & Flow
1. Developer invokes a local build command (`flutter run` / `flutter build`)
2. Build flavor determines:
   - Environment configuration
   - Logging verbosity
   - Feature availability
3. Flutter toolchain compiles Dart → platform-specific artifacts
4. Artifacts are either:
   - Installed locally (debug)
   - Prepared for store upload (release)

#### Edge Cases & Failure Modes
- Mismatched Flutter SDK version causes build failure
- Incorrect environment flags may:
  - Point production builds at dev services
  - Enable debug-only features in release
- Platform-specific signing issues block release builds

#### Future Extensions
- CI-based build automation (GitHub Actions / GitLab CI)
- Reproducible build verification via checksums
- Build metadata injection (commit hash, build time)

---

#### 14.1.1 Local Builds

#### Overview
Local builds are used for development, debugging, and manual QA prior to distribution.

#### Responsibilities
- Enable fast iteration during development
- Allow platform-specific testing without store deployment
- Surface runtime errors early

#### State & Flow
- Common commands:
  - `flutter run` (debug, hot reload enabled)
  - `flutter build apk` / `flutter build ios`
- Build flavor selected via:
  - Dart defines
  - Flavor-specific entrypoints (if applicable)

#### Assumptions
- Developers have the correct Flutter SDK installed
- Platform SDKs (Android Studio / Xcode) are properly configured

#### Open Questions
- Are multiple Flutter flavors currently defined, or is a single entrypoint used with runtime flags?
- Is there a canonical build command documented for contributors?

---

### 14.2 Platform Deployment

#### Overview
Covers how AshTrail is packaged and distributed to end users via platform-specific app stores.

#### Responsibilities
- Produce store-compliant binaries
- Manage signing and provisioning
- Ensure store metadata aligns with app behavior

---

#### 14.2.1 Android

#### Overview
Android builds are distributed via APK/AAB artifacts and installed through the Play Store or sideloading for testing.

#### Responsibilities
- Generate signed release builds
- Manage application ID and version codes
- Comply with Play Store policies

#### State & Flow
1. `flutter build appbundle` or `flutter build apk`
2. Gradle handles:
   - Signing configuration
   - Version code/name injection
3. Output uploaded to:
   - Play Console (production/testing)
   - Direct install for internal testing

#### Edge Cases & Failure Modes
- Incorrect keystore configuration blocks release builds
- Version code reuse rejected by Play Store
- ABI misconfiguration increases binary size or breaks installs

#### Assumptions
- Android signing keys are stored securely and backed up
- Play Store is the primary distribution channel

---

#### 14.2.2 iOS

#### Overview
iOS builds are distributed through TestFlight and the App Store.

#### Responsibilities
- Manage certificates and provisioning profiles
- Ensure App Store compliance
- Handle Apple-specific build constraints

#### State & Flow
1. `flutter build ios` (release)
2. Xcode performs:
   - Code signing
   - Archive generation
3. Archive uploaded via:
   - Xcode Organizer
   - Transporter
4. Distribution through TestFlight → App Store

#### Edge Cases & Failure Modes
- Expired certificates prevent builds
- Provisioning profile mismatch blocks signing
- App Store review rejection due to policy violations

#### Assumptions
- Apple Developer account is active
- iOS deployment target matches supported devices

---

### 14.3 Versioning

#### Overview
Defines how application versions and internal schemas evolve over time without breaking existing users.

#### Responsibilities
- Track application releases
- Maintain backward compatibility where required
- Coordinate app version with data schema version

---

#### 14.3.1 Schema Versioning

#### Overview
Schema versioning ensures persisted data remains readable across app updates.

#### Responsibilities
- Identify breaking changes to local data models
- Migrate or invalidate incompatible data safely
- Prevent silent data corruption

#### Data Structures
- **Schema Version**
  - Type: integer
  - Scope: local persistence layer
  - Stored alongside persisted data

#### State & Flow
1. App startup reads persisted schema version
2. Current app schema version is compared
3. If versions differ:
   - Compatible → migrate
   - Incompatible → reset or block load
4. Updated schema version is persisted

#### Edge Cases & Failure Modes
- Downgrade to older app version cannot read newer schema
- Partial migrations leave data in inconsistent state
- Missing schema version defaults incorrectly

#### Assumptions
- Local persistence supports schema metadata
- Migrations are deterministic and idempotent

#### Open Questions
- Are schema migrations currently implemented or planned?
- Is data reset acceptable on breaking schema changes, or must data always be preserved?

#### Future Extensions
- Formal migration framework
- Per-entity schema versioning
- Migration test coverage

---

---

<!-- FILE: 15. Assumptions & Open Questions.md -->

<a id="15-assumptions-&-open-questions"></a>

## 15. Assumptions & Open Questions

### 15.1 Overview

This section documents explicit assumptions made during the design and implementation of AshTrail, along with unresolved questions that may affect future architecture, scalability, or feature direction.

These assumptions are intentionally documented to:
- Clarify current design tradeoffs
- Prevent accidental violations during future development
- Provide context for refactors or extensions

---

### 15.2 Assumptions

#### 15.2.1 Single Primary User

**Description**
- AshTrail is currently designed with the expectation that a single human user operates the app.
- Multiple accounts exist to represent different tracking contexts (e.g., substances, profiles), not different people.

**Implications**
- No concurrency control between users
- No permission or role model
- Local state is authoritative per device
- Sync conflicts are resolved under the assumption of a single actor

**Constraints**
- Account switching is local and deterministic
- All logs are assumed to originate from the same person
- UX does not account for collaborative or shared editing

**Assumptions**
- The user will not attempt to use AshTrail collaboratively
- Multi-device usage is limited to the same individual

---

#### 15.2.2 Eventual Consistency Is Acceptable

**Description**
- AshTrail tolerates temporary divergence between local and remote state.
- Local-first behavior is prioritized over immediate global correctness.

**Implications**
- Logs may appear locally before syncing remotely
- Aggregations may lag behind recent writes
- Temporary inconsistencies are expected during offline usage

**Constraints**
- No hard real-time guarantees
- Sync failures must not block local usage
- Conflict resolution favors latest-known or locally-authoritative data

**Assumptions**
- Short-term inconsistency does not harm the core use case
- Users value reliability and offline access over strict immediacy

---

### 15.3 Open Questions

#### 15.3.1 Multi-User Expansion

**Question**
- Will AshTrail ever support multiple human users sharing data or collaborating?

**Potential Impact**
- Authentication model would need to expand beyond account switching
- Permissions, ownership, and access control would be required
- Sync and conflict resolution logic would become significantly more complex
- Aggregation and analytics would need user-scoping

**Open Considerations**
- Is multi-user a hard requirement or an optional future tier?
- Would shared data be read-only, write-only, or fully collaborative?
- Would users share devices or operate independently?

---

#### 15.3.2 Server-Side Aggregation

**Question**
- Should aggregation and analytics eventually move partially or fully to the server?

**Potential Impact**
- Reduced client computation and battery usage
- More consistent cross-device analytics
- Increased backend complexity and cost
- Requires trust in server-side correctness

**Open Considerations**
- Are aggregations needed across devices or accounts?
- Is historical recomputation required if logic changes?
- Should the server be authoritative for derived data, or only raw logs?

---

### 15.4 Notes

- These assumptions are not guarantees; violating them may cause undefined behavior.
- Any future feature work should explicitly confirm whether these assumptions still hold.
- If an assumption becomes invalid, this section must be updated before implementation proceeds.

---

---

<!-- FILE: 16. Future Extensions.md -->

<a id="16-future-extensions"></a>

## 16. Future Extensions

> This section documents **explicitly non-implemented** but planned or plausible extensions.  
> Nothing in this section should be assumed to exist in the current codebase.

---

### 16.1 Advanced Analytics

#### 16.1.1 Predictive Models

##### Overview
Potential future capability to analyze historical log data and generate forward-looking insights (e.g., usage trends, risk indicators).

##### Responsibilities
- Consume historical log entries across one or more accounts
- Generate derived metrics or predictions
- Surface results in a read-only, advisory capacity

##### Data Structures
_Not implemented._

Expected inputs:
- LogEntry (existing domain model)
- Aggregated time windows (daily / rolling)

Expected outputs:
- PredictionResult (derived, ephemeral)
  - `metricName: string`
  - `timeHorizon: Duration`
  - `predictedValue: num`
  - `confidence?: num`

##### State & Flow
- Read-only access to persisted logs
- Computation performed on-demand or via background job
- Results are **never** written back as authoritative log data

##### Edge Cases & Failure Modes
- Sparse or inconsistent historical data
- Multi-account contamination if scoping is incorrect
- Overfitting or misleading outputs

##### Assumptions
- Predictions are advisory, not prescriptive
- No medical or health claims are made

##### Open Questions
- Should models run locally only, or allow opt-in external compute?
- Are predictions per-account or cross-account?
- How are confidence levels communicated to users?

---

### 16.2 External Integrations

#### 16.2.1 Wearables

##### Overview
Potential integration with third-party wearable devices to enrich logs with contextual or passive data.

##### Responsibilities
- Authenticate with external providers
- Ingest time-series data
- Correlate external signals with internal logs

##### Data Structures
_Not implemented._

Expected external inputs:
- Timestamped sensor records (format provider-specific)

Expected internal mapping:
- ExternalRecord → DerivedContext (non-authoritative)

##### State & Flow
- External sync occurs independently of manual logging
- Imported data is **annotative**, not a source of truth
- No automatic log creation without explicit user action

##### Edge Cases & Failure Modes
- Clock drift between devices
- Partial syncs or missing intervals
- API rate limits or provider outages

##### Assumptions
- All integrations are optional and revocable
- No background sync without user consent

##### Open Questions
- Which providers are in scope (Apple Health, Google Fit, etc.)?
- Is data stored raw or normalized?
- How is external data visually distinguished?

---

### 16.3 Data Export

#### 16.3.1 CSV

##### Overview
Allow users to export structured log data for external analysis.

##### Responsibilities
- Serialize logs into flat, tabular format
- Preserve ordering and timestamps
- Respect active account boundaries

##### Data Structures
Export schema (example):
- `timestamp`
- `accountId`
- `duration`
- `notes?`
- `tags?`

##### State & Flow
- Triggered manually by user
- Export generated from local database
- No mutation of underlying data

##### Edge Cases & Failure Modes
- Large exports impacting memory
- Locale-specific formatting (dates, decimals)
- CSV injection risks

##### Open Questions
- Should exports be scoped by date range?
- Should tags be flattened or expanded?

---

#### 16.3.2 JSON

##### Overview
Machine-readable export intended for re-import or automation.

##### Responsibilities
- Emit structured, lossless representations
- Maintain schema versioning

##### Data Structures
- `ExportBundle`
  - `schemaVersion: string`
  - `exportedAt: DateTime`
  - `accounts: Account[]`
  - `logs: LogEntry[]`

##### State & Flow
- User-initiated
- Stateless generation
- Output is immutable

##### Edge Cases & Failure Modes
- Schema drift across app versions
- Partial exports if interrupted

##### Open Questions
- Should imports from JSON be supported later?
- How strict should schema validation be?

---

### 16.4 Automation

#### 16.4.1 Scheduled Summaries

##### Overview
Automatically generate periodic summaries of logging activity.

##### Responsibilities
- Aggregate logs over a defined window
- Produce human-readable summaries
- Deliver summaries without requiring app interaction

##### Data Structures
_Not implemented._

Expected derived artifacts:
- SummaryReport
  - `periodStart`
  - `periodEnd`
  - `metrics`
  - `notes`

##### State & Flow
- Background scheduler triggers aggregation
- Summaries are derived, not stored as logs
- Delivery via in-app view or notification

##### Edge Cases & Failure Modes
- App suspended or background execution restricted
- Missed schedules due to OS constraints
- Timezone changes mid-period

##### Assumptions
- Automation respects OS battery and background limits
- Users can disable or modify schedules

##### Open Questions
- Daily vs weekly vs rolling summaries?
- Are summaries persisted or ephemeral?
- Should summaries be per-account or global?

---

### Summary Constraints

- All future extensions are **opt-in**
- No extension may mutate historical log data
- Core logging remains authoritative
- Extensions must degrade gracefully when unavailable

---

---

<!-- FILE: 17. Performance & Scalability.md -->

<a id="17-performance-&-scalability"></a>

## 17. Performance & Scalability

### 17.1 Performance Targets

#### 17.1.1 App Startup Time

**Overview**  
Defines acceptable startup latency to ensure the app feels responsive and usable on first launch and resume.

**Responsibilities**
- Minimize time to first interactive frame
- Avoid blocking I/O or synchronous initialization on startup
- Defer non-critical initialization

**Targets**
- Cold start (app not resident): ≤ 1.5 seconds on mid-range devices
- Warm start (app in memory): ≤ 500 ms
- Resume from background: ≤ 300 ms

**State & Flow**
- App launches
- Core services initialize (config, local DB, account state)
- UI renders minimal shell
- Deferred services initialize asynchronously

**Edge Cases & Failure Modes**
- Slow disk I/O during local database initialization
- Corrupt local cache causing blocking recovery logic
- Excessive synchronous providers during startup

**Future Extensions**
- Startup tracing and metrics collection
- Lazy-loading of non-critical providers


#### 17.1.2 Log Entry Creation Latency

**Overview**  
Ensures log creation feels instantaneous to the user.

**Responsibilities**
- Capture user input
- Persist log locally
- Update UI state immediately

**Targets**
- End-to-end latency (tap → UI confirmation): ≤ 100 ms
- Local write latency: ≤ 50 ms

**State & Flow**
- User submits log
- Log is validated synchronously
- Log written to local database
- UI state updates optimistically

**Edge Cases & Failure Modes**
- Disk contention delaying writes
- Validation errors blocking persistence
- Large datasets increasing write overhead

**Future Extensions**
- Background batching for non-critical fields
- Write-ahead logging or buffering


---

### 17.2 Local Database Performance

#### 17.2.1 Index Usage

**Overview**  
Indexes ensure predictable query performance as data volume grows.

**Responsibilities**
- Maintain indexes for common query patterns
- Avoid unnecessary or redundant indexes

**Expected Indexes**
- Account ID
- Timestamp (descending)
- Sync status

**Constraints**
- Index creation must not block app startup
- Index updates must occur automatically on write

**Edge Cases & Failure Modes**
- Missing index causing full-table scans
- Index bloat increasing memory usage

**Open Questions**
- Should compound indexes be introduced for analytics queries?


#### 17.2.2 Query Patterns

**Overview**  
Defines supported and optimized query shapes.

**Common Patterns**
- Fetch recent logs for active account
- Fetch logs within time range
- Aggregate logs by day/week

**Constraints**
- Queries must be bounded (limit/offset or time window)
- No unbounded full-history scans in UI paths

**Edge Cases & Failure Modes**
- Large result sets causing UI jank
- Inefficient aggregation queries on-device

**Future Extensions**
- Pre-aggregated summaries
- Materialized views for analytics


---

### 17.3 Memory Management

#### 17.3.1 Large Dataset Handling

**Overview**  
Ensures the app remains stable with long-term usage and large datasets.

**Responsibilities**
- Avoid loading full datasets into memory
- Stream or paginate data where possible

**Strategies**
- Pagination for history views
- Windowed queries for analytics
- Dispose unused providers promptly

**Constraints**
- No in-memory caching of entire log history
- Charts must operate on reduced datasets

**Edge Cases & Failure Modes**
- Memory pressure on low-RAM devices
- Provider leaks retaining large lists

**Future Extensions**
- Background compaction or archiving
- Configurable data retention policies


---

### 17.4 Sync Performance

#### 17.4.1 Batch Sizes

**Overview**  
Controls how local logs are uploaded or synced efficiently.

**Responsibilities**
- Group multiple log entries per sync operation
- Balance throughput vs. memory usage

**Assumed Defaults**
- Batch size: 50–100 log entries
- Max payload size aligned with backend limits

**State & Flow**
- Identify unsynced logs
- Group into batches
- Upload sequentially or with limited parallelism

**Edge Cases & Failure Modes**
- Oversized batches causing request failures
- Too-small batches increasing overhead

**Open Questions**
- Should batch size adapt dynamically based on network conditions?


#### 17.4.2 Throttling Rules

**Overview**  
Prevents excessive sync attempts and conserves resources.

**Responsibilities**
- Limit sync frequency
- Back off on repeated failures

**Rules**
- Minimum interval between sync attempts
- Exponential backoff on errors
- Pause sync when offline or backgrounded

**Edge Cases & Failure Modes**
- Sync storms after reconnect
- Starvation if backoff never resets

**Future Extensions**
- Network-aware throttling
- User-configurable sync behavior


---

### 17.5 Scalability Assumptions

#### 17.5.1 Single-User Data Volume Limits

**Overview**  
Defines expected data scale to guide architectural decisions.

**Assumptions**
- Single primary user per app install
- No concurrent multi-user write access

**Estimated Limits**
- Log entries: up to ~100,000 per user
- Data growth: linear over time
- Sync backend scales independently

**Constraints**
- Local storage must handle multi-year usage
- Performance must degrade gracefully beyond expected limits

**Edge Cases & Failure Modes**
- Unexpected data spikes
- Migration issues with very large datasets

**Open Questions**
- Should hard caps or warnings be enforced?
- Is long-term archival required?

---

---

<!-- FILE: 18. Data Integrity & Consistency.md -->

<a id="18-data-integrity-&-consistency"></a>

## 18. Data Integrity & Consistency

### Overview
This section defines how AshTrail preserves correctness, prevents corruption, and maintains consistent behavior across local and remote data stores. It exists to ensure that user logs remain accurate, non-duplicated, and recoverable under offline-first and eventual-consistency constraints.

---

### 18.1 Source of Truth

### Overview
Defines which data store is authoritative in different operating modes (offline vs online) and how conflicts are resolved.

### Responsibilities
- Establish clear authority boundaries between local storage and remote sync targets.
- Prevent accidental overwrites during synchronization.
- Ensure deterministic conflict resolution.

### 18.1.1 Local vs Remote Authority

#### Rules
- **Local database is the primary source of truth**
  - All user actions write to local storage first.
  - UI always reflects local state.
- **Remote storage is a replication target**
  - Used for backup, cross-device continuity, and analytics.
  - Never blocks local writes.

#### Conflict Resolution
- Conflicts are resolved in favor of **local state** unless explicitly overridden.
- Remote data is treated as:
  - Stale
  - Incomplete
  - Potentially conflicting

#### Assumptions
- The user may operate fully offline for extended periods.
- Remote writes may fail or be delayed without user awareness.

#### Open Questions
- Should remote deletions ever propagate back to local state?
- Is there a scenario where remote data should override local data?

---

### 18.2 Idempotency

### Overview
Ensures that repeated operations (especially sync-related) do not create duplicate or corrupted data.

### Responsibilities
- Guarantee safe retries for sync and persistence operations.
- Prevent double-application of the same mutation.

### 18.2.1 Sync Operations

#### Idempotency Strategy
- Each log entry has a **stable, client-generated unique identifier**.
- Sync operations use **upsert semantics**, not inserts.
- Replaying the same sync payload must result in no net change.

#### Constraints
- Identifiers must:
  - Be generated before persistence.
  - Remain immutable for the life of the record.
- Sync operations must be:
  - Stateless
  - Retry-safe

#### Failure Modes
- Network retries
- App restarts mid-sync
- Partial batch uploads

---

### 18.3 Duplicate Prevention

### Overview
Prevents multiple records from representing the same real-world event.

### Responsibilities
- Detect and block duplicate creation at the earliest possible stage.
- Avoid reliance on backend-only deduplication.

### 18.3.1 Client-Side Guards

#### Mechanisms
- UUID-based primary keys generated client-side.
- Single-write flow for log creation:
  - UI → Domain → Local persistence
- No background process allowed to create logs autonomously.

#### Constraints
- A log entry is considered immutable after creation.
- Editing creates a new revision or replacement record (if supported).

#### Edge Cases
- Rapid repeated user input
- App crashes immediately after submission
- User manually re-entering identical data

---

### 18.4 Schema Evolution

### Overview
Defines how data models evolve without breaking existing installs or corrupting stored data.

### Responsibilities
- Support older data formats.
- Prevent data loss during upgrades.
- Make migrations explicit and reversible when possible.

### 18.4.1 Backward Compatibility

#### Strategy
- Schema changes must be additive whenever possible.
- Fields may be:
  - Added with defaults
  - Deprecated but not immediately removed
- Deserialization must tolerate missing fields.

#### Migration Rules
- Migrations run:
  - On app startup
  - Before data is accessed by the UI
- Failed migrations must:
  - Abort safely
  - Preserve original data

#### Assumptions
- Users may skip multiple app versions.
- Downgrades are not officially supported.

#### Open Questions
- Should schema versions be stored per-record or per-database?
- Is partial migration acceptable, or must it be all-or-nothing?

---

### 18.5 Data Repair Tools

### Overview
Provides mechanisms to recover from corruption, user error, or unexpected failures.

### Responsibilities
- Allow safe inspection and recovery of local data.
- Avoid silent data loss.

### 18.5.1 Manual Recovery Options

#### Planned Capabilities
- Clear local cache while preserving account metadata.
- Rebuild derived or aggregated data from raw logs.
- Export raw local data for external inspection.

#### Non-Goals
- Automatic silent repair without user awareness.
- Remote-triggered destructive operations.

#### Failure Modes Addressed
- Corrupted local database
- Interrupted migrations
- Partial sync states

#### Open Questions
- Should recovery tools be developer-only or user-accessible?
- Is a read-only “safe mode” needed for diagnostics?

---

### Summary Constraints

- Local storage is authoritative.
- All operations must be retry-safe.
- Duplicate creation must be prevented at the client layer.
- Schema changes must not invalidate existing data.
- Recovery paths must favor transparency over automation.

---

---

<!-- FILE: 19. Time, Locale, and Timezone Handling.md -->

<a id="19-time,-locale,-and-timezone-handling"></a>

## 19. Time, Locale, and Timezone Handling

### 19.0 Overview

This section defines how AshTrail handles time, dates, timezones, and locale-specific formatting to ensure consistency across logging, aggregation, display, and synchronization.

Time handling is treated as a **core correctness concern** due to:
- Daily aggregations and trends
- Cross-midnight logging behavior
- Offline-first data creation
- Future sync and analytics use cases

---

### 19.1 Responsibilities

The time and locale system is responsible for:

- Ensuring all stored timestamps are unambiguous and comparable
- Providing consistent day-boundary calculations
- Preventing timezone-related data corruption
- Separating **storage concerns** from **display concerns**
- Supporting deterministic analytics and aggregation

Non-responsibilities:
- No timezone conversion at write time beyond normalization
- No historical reinterpretation of timestamps once persisted
- No user-facing timezone configuration (unless explicitly added later)

---

### 19.2 Data Structures

#### 19.2.1 Timestamp Fields

All persisted time values must follow these rules:

| Field | Type | Constraints |
|-----|------|------------|
| `timestampUtc` | `DateTime` | Required, UTC, ISO-8601 |
| `localOffsetMinutes` | `int?` | Optional, captured at creation |
| `localDateKey` | `String` | Required, derived local calendar date |

Notes:
- `timestampUtc` is the **source of truth**
- `localDateKey` is used for daily grouping
- `localOffsetMinutes` is informational and diagnostic

---

### 19.3 State & Flow

#### 19.3.1 Timestamp Creation Flow

1. User initiates a log entry
2. System obtains current time via shared time abstraction
3. Timestamp is normalized to UTC
4. Local offset and derived local date are computed
5. All values are persisted together

Rules:
- `DateTime.now()` must not be called directly
- All time access flows through a single abstraction layer

---

### 19.4 Timezone Strategy

#### 19.4.1 Stored Timezone

- All timestamps are stored in **UTC**
- No local timezone identifiers are persisted
- No automatic migration on timezone changes

Rationale:
- Prevents ambiguity
- Simplifies comparison and sync
- Avoids DST-related corruption

#### 19.4.2 Display Timezone

- UI converts UTC timestamps to **device-local timezone**
- Conversion occurs at render time only
- Aggregations never rely on display-time conversions

---

### 19.5 Day Boundary Rules

#### 19.5.1 Cross-Midnight Sessions

Rules for log entries that span midnight:
- The **start time** determines the `localDateKey`
- Duration is not split across days
- Aggregations respect the assigned `localDateKey`

Explicit non-behavior:
- No automatic session splitting
- No retroactive reassignment

Rationale:
- Predictable behavior
- Simplified analytics
- Matches user mental model of “when it started”

---

### 19.6 Locale Formatting

Locale affects **presentation only**, never storage.

#### 19.6.1 Dates

- Rendered using device locale
- Examples:
  - `MM/DD/YYYY` (US)
  - `DD/MM/YYYY` (EU)
- Internal date keys remain locale-independent

#### 19.6.2 Numbers

- Duration and numeric values formatted using locale rules
- Decimal separators and grouping are presentation-only
- Stored values remain raw numeric types

---

### 19.7 Edge Cases & Failure Modes

#### 19.7.1 DST Transitions

Handled by design via UTC storage:

- DST start/end does not affect stored timestamps
- Local offset is captured at creation time only
- No recalculation occurs post-persistence

Known behaviors:
- A “day” may appear shorter or longer in local display
- Aggregations remain stable and deterministic

---

### 19.8 Assumptions

- Device clock is reasonably accurate
- UTC is acceptable as the canonical time reference
- Users do not require historical timezone reinterpretation

---

### 19.9 Open Questions

- Should time access be injectable for deterministic testing?
- Should `localOffsetMinutes` be required instead of optional?
- Should users be able to override day-boundary behavior?
- Is timezone-aware export needed for external data consumers?

---

### 19.10 Future Extensions

- User-configurable day start offset (e.g., 4am–4am)
- Explicit timezone capture (IANA identifiers)
- Timezone-aware data export options
- Cross-device timezone reconciliation

---

---

<!-- FILE: 20. Security Model.md -->

<a id="20-security-model"></a>

## 20. Security Model

### 20.1 Overview

This section defines the security assumptions, controls, and known limitations of AshTrail.
The security model is intentionally conservative and scoped to a **single-user, client-centric application** with optional cloud sync via Firebase.

AshTrail does **not** attempt to defend against a fully compromised device or a determined, well-resourced attacker. It prioritizes:
- Accidental data exposure prevention
- Proper access isolation between accounts
- Secure data transport
- Reasonable local data protection within platform constraints

---

### 20.2 Responsibilities

The security model is responsible for:
- Defining who AshTrail defends against
- Establishing boundaries of trust (client vs network vs backend)
- Ensuring Firestore access is correctly scoped per account
- Preventing cross-account data leakage
- Documenting risks inherent to offline-first storage

Out of scope:
- Malware-level device compromise
- Rooted / jailbroken device protections
- Forensic-grade local encryption guarantees

---

### 20.3 Threat Model

### 20.3.1 Assumed Adversaries

AshTrail assumes the following adversary profiles:

**In Scope**
- Curious local user with temporary device access
- Accidental data exposure (logs, backups, debug builds)
- Misconfigured Firebase rules
- Network-level passive observers (e.g., public Wi-Fi)

**Out of Scope**
- Malicious apps with root / system privileges
- Physical attackers with extended device access
- Nation-state or targeted surveillance actors
- Firebase project owner compromise

**Key Assumption**
- If the device is fully compromised, AshTrail data is considered compromised.

---

### 20.4 Client-Side Security

### 20.4.1 Local Data Protection

Local persistence is implemented using Hive (or equivalent local storage).

**Protections**
- Data is sandboxed per platform (iOS / Android app sandbox)
- No shared storage or external storage usage
- No plaintext exports without explicit user action
- Account switching clears in-memory state

**Limitations**
- Local data is readable on rooted / jailbroken devices
- OS-level backups may include local data unless excluded
- No per-record encryption keys
- No biometric or passcode gating (currently)

**Assumptions**
- OS sandboxing provides baseline isolation
- User trusts their own device environment

---

### 20.5 Network Security

### 20.5.1 TLS Assumptions

All network communication relies on Firebase SDK defaults.

**Assumptions**
- TLS is enforced for all client–Firebase communication
- Certificate validation is handled by the platform SDK
- No custom HTTP clients bypassing TLS

**Out of Scope**
- Certificate pinning
- Custom transport-layer security logic
- Defense against compromised root CAs

---

### 20.6 Firebase Rules

### 20.6.1 Firestore Access Control

Firestore is the primary remote data store when sync is enabled.

**Core Rules Principles**
- Users may only read/write documents belonging to their account
- Account ID must match authenticated user context
- No public or anonymous read access
- No cross-account queries

**Expected Rule Constraints**
- `request.auth != null`
- `request.auth.uid == resource.data.accountId`
- Collection paths scoped by account identifier

**Failure Impact**
- Misconfigured rules can result in:
  - Cross-user data exposure
  - Unauthorized writes
  - Silent data corruption

**Assumption**
- Firebase Authentication is the sole identity provider

---

### 20.7 Known Limitations

### 20.7.1 Offline Exposure Risks

AshTrail is offline-first by design, which introduces unavoidable risks.

**Risks**
- Local logs are accessible if the device is compromised
- Offline data cannot be remotely revoked or wiped
- Deleted remote data may persist locally until sync

**Non-Goals**
- Full disk encryption management
- Secure enclave integration
- Remote kill-switch behavior

**Tradeoff Rationale**
- Offline-first usability is prioritized over strict zero-trust enforcement
- App is designed for personal use, not regulated environments

---

### 20.8 Edge Cases & Failure Modes

- User signs out but local storage remains intact
- Account switching without full app restart
- Debug builds exposing logs or stack traces
- Firebase rule regression during deployment
- Partial sync failures leaving stale local data

---

### 20.9 Future Extensions (Explicitly Non-Implemented)

- Local encryption with user-derived keys
- Biometric or passcode-protected app access
- Per-account encrypted Hive boxes
- Remote wipe on account invalidation
- Certificate pinning
- Audit logging for security events

---

### 20.10 Assumptions & Open Questions

### Assumptions
- Single primary user per device
- Firebase Authentication remains trusted
- OS sandboxing is sufficient for baseline security

### Open Questions
- Should local storage be encrypted by default?
- Should app access require biometric authentication?
- Should account sign-out trigger local data purge?
- Should sensitive analytics be opt-in only?

---

---

---

<!-- FILE: 21. Permissions & OS Integration.md -->

<a id="21-permissions-&-os-integration"></a>

## 21. Permissions & OS Integration

### 21.1 Overview

This section documents how AshTrail interacts with mobile operating systems (Android and iOS) at the permission and OS-integration level.

Goals:
- Clearly define which OS permissions are required vs optional
- Specify behavior when permissions are missing or revoked
- Document platform-specific differences that affect implementation
- Prevent implicit permission creep or undocumented OS dependencies

AshTrail is designed to be **minimally invasive**:
- Core functionality must work with the smallest permission surface possible
- Optional permissions must degrade gracefully when denied

---

### 21.2 Responsibilities

The permissions and OS integration layer is responsible for:

- Declaring required and optional permissions at build time
- Requesting runtime permissions where applicable
- Detecting permission state changes (granted / denied / revoked)
- Adapting app behavior based on permission availability
- Avoiding crashes or undefined behavior when permissions are missing

---

### 21.3 Required Permissions

#### 21.3.1 Network Access

**Purpose**
- Sync log records with the remote backend
- Authenticate users
- Fetch account metadata

**Scope**
- Outbound HTTPS requests only
- No background socket listeners
- No peer-to-peer networking

**Platform Details**

| Platform | Permission | Notes |
|--------|-----------|------|
| Android | `INTERNET` | Normal permission; auto-granted at install |
| iOS | None explicit | Network access allowed by default; constrained by App Transport Security |

**Constraints**
- App must continue functioning offline if network access is unavailable
- Network failures are treated as transient, not fatal

---

### 21.4 Optional Permissions

#### 21.4.1 Notifications

**Purpose**
- Future reminders or summaries (e.g., daily usage insights)
- Potential alerting for streaks or thresholds

**Current Status**
- Optional
- Not required for core logging or analytics
- Must not block any user flow

**Platform Details**

| Platform | Permission | Notes |
|--------|-----------|------|
| Android | `POST_NOTIFICATIONS` (API 33+) | Runtime permission |
| iOS | User notification authorization | Explicit user prompt required |

**Behavior When Denied**
- No retry loops or repeated prompts
- Feature silently disables itself
- UI should reflect notifications as “off”

---

### 21.5 Platform Differences

#### 21.5.1 Android

**Characteristics**
- Explicit permission declarations in `AndroidManifest.xml`
- Runtime permission checks required for notifications (API 33+)
- Network permission is implicit and non-revocable

**Implementation Notes**
- Notification permission request must be deferred until feature usage
- Do not request notification permission at app startup

---

#### 21.5.2 iOS

**Characteristics**
- No explicit network permission
- Notification permissions are user-facing and revocable
- OS may silently throttle or suppress notifications

**Implementation Notes**
- App must handle notifications being disabled outside the app
- Permission state should be re-checked on app resume

---

### 21.6 State & Flow

**Permission Evaluation Flow**
1. App initializes
2. Required permissions assumed available (network)
3. Optional permissions checked lazily
4. Feature modules enable/disable themselves based on permission state

**Notification Permission Flow**
- User enables a notification-related feature
- App requests permission
- OS returns grant or denial
- Feature state is persisted and respected

---

### 21.7 Data Structures

**Permission State (Logical Model)**

| Field | Type | Description |
|-----|------|-------------|
| `permissionType` | enum | Network, Notifications |
| `isGranted` | bool | Current OS-reported state |
| `lastCheckedAt` | datetime | Timestamp of last evaluation |

> Note: This may be transient state only and not persisted unless required by UI logic.

---

### 21.8 Failure Modes

#### 21.8.1 Permission Denied Behavior

**Network Unavailable**
- Sync operations fail gracefully
- Local logging remains fully functional
- Retry logic governed by sync subsystem

**Notifications Denied**
- Feature is disabled without error
- No blocking dialogs
- User may manually re-enable via OS settings

**Permission Revoked While App Is Installed**
- App detects change on resume
- Dependent features deactivate
- No crashes or undefined state

---

### 21.9 Assumptions & Open Questions

**Assumptions**
- Network access is always available at install time
- Core functionality does not require any dangerous permissions
- Notifications remain optional indefinitely

**Open Questions**
- Will background sync ever be introduced (may require additional OS constraints)?
- Should notification permission state be persisted for analytics or UX?
- Are platform-specific permission abstractions required in the domain layer?

---

### 21.10 Future Extensions

- Background tasks (may introduce battery or background execution constraints)
- Wearable or system integrations (likely new permission classes)
- Fine-grained notification channels or categories

---

---

<!-- FILE: 22. Notifications & Reminders.md -->

<a id="22-notifications-&-reminders"></a>

## 22. Notifications & Reminders

### 22.1 Overview

This module defines how AshTrail schedules and delivers reminders to prompt the user to create log entries.  
Its purpose is to reduce missed logs while preserving AshTrail’s offline-first and single-primary-user assumptions.

Notifications are **local-only** and do not rely on a backend service.

---

### 22.2 Responsibilities

The Notifications & Reminders system is responsible for:

- Scheduling reminder notifications on the local device
- Triggering notifications at user-configured times
- Ensuring reminders are aware of the currently active account
- Avoiding reminder delivery when notifications are disabled
- Re-registering reminders after app restarts or device reboot (where supported)

Out of scope:

- Cross-device notification synchronization
- Remote push notifications
- Behavioral or adaptive reminder logic (e.g., AI-based timing)

---

### 22.3 Data Structures

> **Note:** Exact persistence strategy must match existing configuration storage (e.g., Hive / local settings store).

#### 22.3.1 Reminder Configuration

| Field | Type | Constraints | Notes |
|---|---|---|---|
| `id` | string | unique | Local identifier for the reminder |
| `accountId` | string | required | Associated account |
| `enabled` | bool | required | Master toggle |
| `timeOfDay` | time | required | Local device time |
| `daysOfWeek` | enum[] | optional | If omitted, assumed daily |
| `createdAt` | datetime | required | For auditing/debug |
| `updatedAt` | datetime | required | For rescheduling logic |

Assumptions:
- All times are stored in **local device time**
- No timezone normalization is performed

---

### 22.4 State & Flow

#### 22.4.1 Scheduling Model

**Local Scheduling Only**

- Reminders are scheduled using platform-native local notification APIs
- Scheduling occurs when:
  - Reminder is created or updated
  - App starts
  - Active account changes
- Each reminder is registered independently

Flow:

1. User enables or updates a reminder
2. Reminder configuration is persisted locally
3. Platform scheduler registers a local notification
4. At trigger time, OS delivers the notification
5. App opens to logging screen when notification is tapped

No background execution is assumed beyond OS-level scheduling.

---

### 22.5 State Interaction

#### 22.5.1 Account Awareness

- Reminders are scoped to an `accountId`
- Only reminders belonging to the **active account** may be scheduled
- On account switch:
  - Existing scheduled reminders are canceled
  - Reminders for the new account are scheduled

Rationale:
- Prevents reminders firing for inactive or hidden accounts
- Aligns with AshTrail’s explicit account switching model

---

### 22.6 Edge Cases & Failure Modes

#### 22.6.1 Device Reboot

- Local notifications may be cleared on reboot (platform-dependent)
- On app launch:
  - All enabled reminders for the active account are re-registered
- If the app is never reopened:
  - Reminders may not fire (accepted limitation)

#### 22.6.2 Permissions Denied

- If notification permissions are denied:
  - Reminders remain configured but inactive
  - UI must reflect disabled delivery state
- No retry loop or nagging behavior is implemented

#### 22.6.3 Time Changes

- Manual device time changes may cause:
  - Missed notifications
  - Duplicate notifications
- No correction logic is implemented beyond next scheduled trigger

---

### 22.7 Future Extensions

> **Explicitly not implemented**

- Remote push notifications
- Smart reminders based on usage patterns
- Reminder analytics or completion tracking

---

### 22.8 Open Questions

#### 22.8.1 Cross-Device Sync

- Should reminders sync across devices for the same account?
- If yes:
  - What is the source of truth?
  - How are conflicts resolved?
- If no:
  - Should this be explicitly documented as a limitation?

#### 22.8.2 Multiple Reminders per Account

- Is more than one reminder per account allowed?
- If restricted:
  - Should enforcement be at UI or data layer?

#### 22.8.3 Missed Reminder Handling

- Should the app surface missed reminders when opened later?
- Or are missed notifications silently ignored?

These questions must be resolved before expanding reminder functionality.

---

---

<!-- FILE: 23. Import - Export.md -->

<a id="23-import---export"></a>

## 23. Import / Export

### 23.1 Overview

The Import / Export subsystem enables users to extract AshTrail data for external analysis, backup, or migration, and to re-ingest previously exported data back into the app.

This subsystem exists to:
- Provide user-owned data portability
- Support manual backups and restores
- Enable analysis outside the app (e.g., spreadsheets, scripts)
- Allow migration between devices or accounts without relying on cloud sync

Import / Export is explicitly **offline-first** and operates on **local persisted data**.

---

### 23.2 Responsibilities

- Serialize persisted domain data into supported export formats
- Scope exports to a single logical account
- Validate imported data before mutation
- Prevent corruption of existing data
- Surface partial or failed imports clearly to the user
- Avoid implicit merging or destructive overwrites

Non-responsibilities:
- No automatic cloud uploads
- No background sync
- No cross-account merging
- No schema migration beyond basic validation

---

### 23.3 Data Structures

#### 23.3.1 Export Payload (Logical Model)

Exports are **self-describing** and include minimal metadata.

| Field            | Type        | Required | Notes |
|------------------|------------|----------|------|
| `exportVersion`  | string     | yes      | Semantic version of export schema |
| `exportedAt`     | datetime   | yes      | ISO-8601 timestamp |
| `accountId`      | string     | yes      | Logical account identifier |
| `accountName`    | string     | yes      | Human-readable account name |
| `logs`           | array      | yes      | Log records for the account |
| `settings`       | object?    | no       | Account-scoped settings (if applicable) |

Constraints:
- `logs` must be an array (may be empty)
- `accountId` must match a single account scope
- Unknown fields must be ignored on import

---

### 23.4 Export Formats

#### 23.4.1 CSV

CSV exports are intended for:
- Spreadsheet analysis
- Lightweight data sharing
- Human inspection

Characteristics:
- One row per log entry
- Flat structure (no nested objects)
- Header row included

Example columns:
- `logId`
- `timestamp`
- `value`
- `notes`
- `createdAt`
- `updatedAt`

Constraints:
- Timestamps serialized as ISO-8601 strings
- Null values serialized as empty fields
- Ordering is chronological (ascending by timestamp)

Limitations:
- Lossy compared to JSON
- Cannot represent nested or future fields cleanly

---

#### 23.4.2 JSON

JSON exports are intended for:
- Full-fidelity backups
- Round-trip import
- Programmatic processing

Characteristics:
- Preserves full object structure
- Includes metadata envelope
- Forward-compatible via ignored unknown fields

Constraints:
- UTF-8 encoded
- Pretty-printing optional (implementation detail)
- Must include `exportVersion`

---

### 23.5 Export Scope

#### 23.5.1 Per Account

Exports are scoped to **exactly one account**.

Rules:
- Only data belonging to the selected account is exported
- No cross-account references are included
- Global app state is excluded

Rationale:
- Prevents accidental data leakage
- Simplifies import semantics
- Aligns with account switching model

---

### 23.6 Import Rules

#### 23.6.1 Validation

All imports must pass validation **before** any data is written.

Validation steps:
1. File format validation (CSV vs JSON)
2. Schema validation
3. Required field presence
4. Type validation
5. Account scope validation

Invalid imports:
- Abort before mutation
- Surface explicit error to user
- No partial writes

---

#### 23.6.2 Conflict Handling

Conflicts occur when imported data collides with existing local data.

Rules:
- Imports never overwrite existing records silently
- Conflicts are detected by stable identifiers (e.g., `logId`)

Default behavior:
- Skip conflicting records
- Import only non-conflicting records

Open question:
- Should the user be prompted to choose between:
  - Skip
  - Replace
  - Duplicate with new ID

(Currently unspecified)

---

### 23.7 State & Flow

#### 23.7.1 Export Flow

1. User selects account
2. User selects export format
3. Data is read from local persistence
4. Data is serialized
5. File is written via OS share/save mechanism

No app state mutation occurs during export.

---

#### 23.7.2 Import Flow

1. User selects file
2. File is parsed
3. Validation runs
4. Conflicts are detected
5. Import plan is constructed
6. Data is written transactionally
7. State is refreshed

Import must be **atomic per record**, not per file.

---

### 23.8 Edge Cases & Failure Modes

#### 23.8.1 Partial Imports

Partial imports may occur when:
- Some records fail validation
- Conflicts are encountered
- User cancels mid-import

Rules:
- Successfully imported records remain
- Failed records are skipped
- User receives a summary:
  - Imported count
  - Skipped count
  - Failure reasons

Partial import must never corrupt:
- Existing records
- Account metadata
- Indexes or aggregates

---

#### 23.8.2 Other Failure Modes

- Unsupported file format
- Corrupt file contents
- Version mismatch
- Out-of-memory on large imports
- Permission denied during file access

All failures must:
- Be surfaced to the user
- Leave local state unchanged (except successful partial imports)

---

### 23.9 Assumptions & Open Questions

Assumptions:
- Import/export is user-initiated only
- Files are provided via OS picker
- Export schema versioning exists

Open Questions:
- Is schema migration supported for older export versions?
- Are account settings included in JSON exports?
- Should CSV imports be supported or export-only?
- Should imports allow creating a new account automatically?

---

### 23.10 Future Extensions

- Encrypted exports
- Compressed export bundles
- Scheduled automatic backups
- Cloud storage integration
- Full account cloning via import
- Diff-based import previews

---

---

<!-- FILE: 24. Developer Workflow.md -->

<a id="24-developer-workflow"></a>

## 24. Developer Workflow
### 24.1 Local Setup
#### 24.1.1 Environment Requirements

**Required tooling**
- Flutter SDK
  - Stable channel
  - Version: *must match the version pinned in the repo*  
    - Assumption: version is defined via `flutter --version` expectation or CI config
- Dart SDK
  - Comes bundled with Flutter
- Platform SDKs
  - Android: Android Studio + SDK tools
  - iOS (macOS only): Xcode + Command Line Tools
- Git
- IDE (recommended, not required)
  - VS Code or Android Studio with Flutter/Dart plugins
  

**Environment configuration**
- Clone repository:
  ```bash

  git clone https://github.com/SoupyOfficial/AshTrail.git

  cd AshTrail
```
- Fetch dependencies:
	```bash
flutter pub get
 ```
 
- Verify setup:
```bash
flutter doctor
```

**Assumptions**
- No local .env file is required
- Environment selection (dev/prod) is handled via build flavors or compile-time flags  

**Open questions**
- Is a specific Flutter version locked via FVM or CI?
- Are platform-specific signing configs required for local builds?


### 24.2 Running the App
#### 24.2.1 Debug Mode
**Standard debug run**
```bash
flutter run
```
- Uses debug flavor by default
- Enables: 
	- Hot reload
	- Verbose error messages
	- Debug logging

**Targeting a specific device**
```bash
flutter devices

flutter run -d <device_id>

Flavor-based execution (if applicable)

flutter run --flavor dev
```

**Assumptions**
- Debug mode uses:  
	- Local database
	- Development backend / Firebase project
- No production data is written during debug runs

**Open questions**
- Are multiple Firebase projects configured per flavor?
- Is debug mode fully offline-capable by default?


### 24.3 Common Tasks
#### 24.3.1 Adding a Log Field

**Typical workflow**
1. Update the domain model  
	- Add field to log record entity/model
2. Update local persistence schema  
	- Hive adapter / serialization logic
3. Update remote sync mapping  
	- Firestore field mapping (if applicable)
4. Update UI  
	- Logging form input
	- Validation rules
5. Update analytics & aggregation logic  
	- Ensure new field is included or explicitly ignored
6. Run migrations (if required)

**Checklist**
- Field added to model
- Serialization updated
- Backward compatibility handled
- UI validation updated
- Analytics unaffected or updated intentionally

**Failure risk**
- Old records missing the new field
- Hive adapter version mismatch

#### 24.3.2 Schema Changes

**Local schema changes**
- Increment adapter version if required
- Provide default values for new fields
- Never remove fields without a migration strategy

**Remote schema changes**
- Firestore is schema-less, but:  
	- Existing documents may not contain new fields
	- Client must handle missing/null values safely
  
**Recommended approach**
- Additive changes only
- Treat all new fields as optional until fully backfilled

**Open questions**
- Is there a formal migration versioning strategy?
- Are destructive schema changes allowed in any environment?

### 24.4 Debugging
#### 24.4.1 Logging Strategy

**Logging levels**
- Debug  
	- State transitions
	- Sync attempts
	- Data parsing
- Info  
	- User actions (non-sensitive)
	- Successful operations
- Error  
	- Failed sync
	- Corrupt data
	- Unexpected state

**Where logs appear**
- Console during debug runs
- Platform logs (Android Logcat / Xcode console)

**Best practices**
- Log state changes, not UI rebuilds
- Include record/account IDs where relevant
- Never log sensitive user data  

**Anti-patterns**
- Logging inside tight UI rebuild loops
- Logging full payloads unnecessarily

### 24.5 Known Gotchas
#### 24.5.1 Hot Reload Caveats

What hot reload does not handle well
- Changes to:  
	- Hive adapters
	- Model constructors
	- Serialization logic
	- Enum values
- Dependency injection graph changes
- Initial app state changes

**Recommended actions**
- Use hot restart instead of hot reload when:  
	- Changing data models
	- Modifying providers that initialize state
- Fully restart app when:  
	- Local schema changes occur
	- Unexpected state behavior appears

**Symptom examples**
- App runs but data appears incorrect
- State not reflecting code changes
- Silent failures after model updates  

**Rule of thumb**
If data shape changed: restart the app.

### 24.6 Future Extensions
- Automated developer bootstrap script
- Pre-commit hooks for formatting and linting
- Schema change checklist enforced via CI
- Local mock data seeding for development
- One-command environment verification

---

---

<!-- FILE: 25. Coding Standards.md -->

<a id="25-coding-standards"></a>

## 25. Coding Standards

### 25.1 Overview

This section defines coding standards for the AshTrail codebase to ensure:
- Consistency across contributors
- Predictable state management
- Clear error-handling semantics
- Low cognitive overhead for future maintainers

These standards apply to all Dart/Flutter code unless explicitly exempted.

---

### 25.2 Responsibilities

The coding standards are responsible for:
- Enforcing consistent naming and file organization
- Preventing accidental state mutation
- Standardizing error-handling patterns
- Defining lint rules that catch issues early

They are **not** responsible for:
- Enforcing architectural boundaries (covered elsewhere)
- Runtime validation or business-rule enforcement

---

### 25.3 Data Structures

_No runtime data structures are introduced by this section._

However, these standards influence how data structures are authored.

---

### 25.4 State & Flow

#### 25.4.1 Naming Conventions

##### 25.4.1.1 Files

Rules:
- `snake_case.dart`
- One primary public construct per file
- File name reflects the main type or responsibility

Examples:
- `log_entry.dart`
- `account_repository.dart`
- `sync_state.dart`

Prohibited:
- `camelCase.dart`
- Mixed responsibilities in a single file
- Abbreviations without clear meaning

---

##### 25.4.1.2 Classes

Rules:
- `PascalCase`
- Nouns for data models
- Verb-noun for services or controllers

Examples:
- `LogEntry`
- `Account`
- `SyncManager`
- `ExportService`

Special cases:
- Abstract classes prefixed with `Base` or suffixed with `Contract`
- Mixins suffixed with `Mixin`

---

#### 25.4.2 Immutability Rules

##### 25.4.2.1 State Objects

Rules:
- All state objects must be immutable
- Fields are `final`
- Updates occur via `copyWith` or full replacement
- No in-place mutation

Required:
- Constructor initializes all required fields
- `copyWith` returns a new instance

Example pattern:
- `State -> NewState = state.copyWith(...)`

Prohibited:
- Mutating collections inside state
- Exposing mutable references
- Late-initialized state fields

Rationale:
- Predictable rebuilds
- Easier debugging
- Safer async flows

---

#### 25.4.3 Error Handling Patterns

##### 25.4.3.1 Result Types vs Exceptions

**Preferred: Result Types**

Use result-style returns for:
- Domain logic
- Validation
- Expected failure modes

Characteristics:
- Explicit success/failure
- Typed error information
- No control-flow via exceptions

**Allowed: Exceptions**

Use exceptions only for:
- Programmer errors
- Invariant violations
- Truly unexpected system failures

Rules:
- Do not use exceptions for normal control flow
- Catch exceptions at system boundaries
- Convert exceptions to user-safe errors before UI

---

#### 25.4.4 Linting

##### 25.4.4.1 Enforced Rules

Linting is mandatory and enforced via analysis configuration.

Expected rules (non-exhaustive):
- No unused imports
- No unused variables
- Prefer `const` constructors
- Avoid dynamic typing
- Explicit return types for public methods

Build impact:
- Lint violations fail CI
- Local builds should surface issues immediately

---

### 25.5 Edge Cases & Failure Modes

- Inconsistent adherence leads to:
  - Hard-to-track state bugs
  - Implicit mutation
  - Unclear error propagation
- Partial compliance is worse than strict enforcement
- Mixing patterns (exceptions + result types) increases complexity

---

### 25.6 Future Extensions

- Formal Result/Error type definition (shared across layers)
- Auto-format enforcement via pre-commit hooks
- Expanded lint rules for architectural constraints
- Documentation linting for public APIs

---

### 25.7 Assumptions & Open Questions

**Assumptions**
- Dart analysis options are already configured in the repo
- All contributors use the same formatter/linter versions

**Open Questions**
- Is there a canonical Result type already in use?
- Are exceptions ever surfaced directly to the UI layer?
- Should architectural linting (layer boundaries) be added later?

---

---

<!-- FILE: 26. Documentation Conventions.md -->

<a id="26-documentation-conventions"></a>

## 26. Documentation Conventions

### 26.1. Overview

This section defines how AshTrail documentation is written and maintained so that:

- Docs render consistently in Obsidian and in plain Markdown viewers.
- Diagrams are version-controlled and reviewable as text.
- Architectural decisions are captured in a consistent format.
- Documentation drift (“doc-rot”) is reduced via explicit update triggers.

### 2. Responsibilities

#### Authors (any contributor)
- Follow Markdown and diagram standards in this document.
- Update docs as part of the same change that modifies behavior, contracts, or architecture.
- Add an ADR when making a non-trivial, non-obvious decision that affects future work.

#### Reviewers
- Treat documentation updates as part of “definition of done” for behavior/architecture changes.
- Enforce heading structure, diagram conventions, and ADR completeness during review.

#### Maintainers
- Keep templates current (ADR template, diagram examples).
- Periodically prune/merge outdated docs (without deleting historical ADRs).

### 3. Data structures (fields, types, constraints)

#### 3.1 Markdown document structure
**Required sections for each major documentation page (recommended standard):**
- Title (H1)
- Sections using H2/H3/H4 as needed
- “Assumptions & Open Questions” when applicable
- “Last updated” metadata (optional but recommended)

**Constraints**
- Use a single H1 per file.
- Do not skip heading levels (H2 → H4 is invalid; must go H2 → H3 → H4).
- Avoid heading depth > H4 unless there is a strong reason (see open questions).

#### 3.2 Diagram blocks (Mermaid)
A diagram is stored as a fenced code block with language `mermaid`.

**Constraints**
- Diagram must be readable as plain text (no “diagram-only” meaning).
- Prefer stable node IDs (avoid auto-generated IDs that change on small edits).
- If the diagram encodes a flow/state machine, keep naming aligned with code identifiers.

**Example**
~~~mermaid
flowchart TD
  A[User action] --> B[State update]
  B --> C{Validation}
  C -- ok --> D[Persist]
  C -- error --> E[Show error]
~~~

##### 3.3 Decision records (ADR)
An ADR is a Markdown document containing a decision and its rationale.

**Recommended file naming**
- `YYYY-MM-DD-short-title.md`

**Recommended directory**
- `docs/adr/`

**ADR fields (required)**
- Title
- Status
- Context
- Decision
- Consequences

**ADR fields (optional)**
- Alternatives considered
- Links
- Follow-ups / TODOs

**ADR template**
	```markdown
	# ADR: <short title>
		
	- Date: YYYY-MM-DD
	- Status: Proposed | Accepted | Deprecated | Superseded
	- Authors: <names/handles>
	
	## Context
	- What problem are we solving?
	- What constraints exist (tech, product, time, security, etc.)?
	
	## Decision
	- What did we decide?
	- What is the scope of this decision?
	- What is explicitly out of scope?
	
	## Consequences
	### Positive
	- ...
	
	### Negative / Trade-offs
	- ...
	
	## Alternatives considered (optional)
	- Option A: ...
	- Option B: ...
	
	## Links (optional)
	- Related PRs/issues:
	- Related docs:
	- Supersedes / superseded by:
	```

### 4. State & flow (how data moves through the system)

### 26.1 Markdown Standards

#### 26.1.1 Heading Depth Rules
- H1: Document title only (one per file).
- H2: Major sections within the doc.
- H3: Subsections.
- H4: Sub-subsections (use sparingly).
- No skipping levels:
  - Valid: H2 → H3 → H4
  - Invalid: H2 → H4
- If a section gets too deep:
  - Split the document into multiple files, or
  - Flatten the structure by moving detail into bullet lists or tables.

**Formatting rules**
- Prefer bullet lists over long paragraphs.
- Prefer tables for stable “reference” information (enums, rules, mappings).
- Keep line lengths readable (soft wrap is fine; avoid walls of text).
- Use code formatting consistently:
  - Inline identifiers: `someIdentifier`
  - File paths: `docs/adr/...`
  - Code blocks for anything multi-line.

### 26.2 Diagrams

#### 26.2.1 Mermaid Usage
Use Mermaid for:
- Flow/state diagrams (user flows, state machines)
- Sequence diagrams (service interactions)
- ER-style sketches (only if they stay readable)

Do not use Mermaid for:
- Pixel-perfect UI mockups
- Diagrams that require heavy styling to be understandable

**Diagram conventions**
- Title diagrams via an immediately preceding heading (H3/H4), not by styling inside the diagram.
- Prefer left-to-right (`LR`) or top-down (`TD`) consistently within a doc.
- Keep diagrams small and composable:
  - If a diagram exceeds ~30 nodes/edges, split it.
- Use labels that match domain terms used in code and documentation.
- When representing a state machine, explicitly label events/triggers.

**Sequence diagram example**
~~~mermaid
sequenceDiagram
  participant UI as UI
  participant SM as State/Controller
  participant DB as Local DB

  UI->>SM: submitLogEntry(payload)
  SM->>SM: validate(payload)
  alt valid
    SM->>DB: insert(entry)
    DB-->>SM: ok
    SM-->>UI: success
  else invalid
    SM-->>UI: validationError
  end
~~~

### 26.3 Decision Records

#### 26.3.1 ADR Format
An ADR is required when a change introduces any of the following:
- A new architectural pattern or dependency that will shape future work.
- A change to persistence, sync, identity/account handling, or security boundaries.
- A trade-off decision that future contributors might otherwise reverse unknowingly.
- A “why” that cannot be inferred from code alone.

**ADR lifecycle**
- Proposed: written during exploration; may change.
- Accepted: decision is implemented (or implementation is actively underway).
- Deprecated: decision is no longer recommended, but may still exist in code.
- Superseded: replaced by a newer ADR (link both ways).

**Linking**
- Link the ADR from the PR/issue description.
- Link the PR/issue back from the ADR.

### 26.4 Keeping Docs in Sync

#### 26.4.1 Update Triggers
Update documentation in the same change when:
- Behavior changes:
  - User-visible flows
  - Validation rules
  - Any persistence/sync semantics
- Contracts change:
  - Public interfaces
  - Data models / schemas
  - File formats (import/export)
- Architecture changes:
  - State management boundaries
  - New services/components/modules
  - Cross-cutting concerns (logging, error handling, security)
- Decisions are made:
  - Add/modify ADRs for non-trivial decisions

**“Docs check” checklist (recommended in PRs)**
- [ ] Updated relevant docs for behavior/contract changes
- [ ] Added/updated Mermaid diagrams if flow/state changed
- [ ] Added ADR if decision is non-obvious and future-relevant
- [ ] Verified headings and code fences render correctly in Obsidian

### 5. Edge cases & failure modes

- **Heading drift / inconsistent structure**
  - Symptom: docs become hard to navigate or duplicate concepts.
  - Mitigation: enforce heading rules; split large docs.

- **Diagram rot**
  - Symptom: Mermaid diagram no longer matches actual flow.
  - Mitigation: require updates when flow changes; keep diagrams small.

- **ADR “status lies”**
  - Symptom: ADR marked Accepted but code never implemented (or reverted).
  - Mitigation: require status updates during follow-up PRs; use Superseded/Deprecated properly.

- **Copy-paste divergence**
  - Symptom: same rule described differently in multiple places.
  - Mitigation: single source of truth; link instead of duplicating.

- **Merge conflicts in docs**
  - Symptom: frequent conflicts in large monolithic docs.
  - Mitigation: split docs by domain; keep files smaller.

### 6. Future extensions (clearly labeled)

- Add a lightweight “docs lint” step:
  - Heading depth validation
  - Broken internal link detection
  - ADR template compliance checks (presence of required headings)

- Add a docs index:
  - `docs/README.md` that links to all major docs and ADRs

- Add standard front matter (if needed):
  - `Owner`, `Last updated`, `Applies to version/flavor`

---

### Assumptions & Open Questions

#### Assumptions
- Documentation lives in-repo (likely under `docs/`) and is intended to be pasted into (or mirrored in) Obsidian.
- Mermaid diagrams are acceptable as “diagrams-as-code” (text-first, VCS-friendly).

#### Open questions
- Where should ADRs live (confirm `docs/adr/` vs another location)?
- Do we want to enforce a maximum heading depth (H4) strictly, or allow deeper nesting in rare cases?
- Should “Docs check” be formalized as a PR template / checklist in the repo?
- Should diagrams be embedded inline only, or also allowed as separate `.mmd` files referenced by docs?

---

---

<!-- FILE: 27. Feature Flags & Experimental Work.md -->

<a id="27-feature-flags-&-experimental-work"></a>

## 27. Feature Flags & Experimental Work

### 1. Overview

Feature flags in AshTrail exist to:
- Reduce risk when shipping incomplete or high-impact changes.
- Support running experiments without forking the codebase.
- Enable rapid rollback by disabling a code path (when implemented as runtime flags).
- Keep development-only tooling out of production builds (compile-time gating).

This section defines:
- A flag strategy split into compile-time vs runtime.
- Rules for experimental feature gating.
- A cleanup/removal policy to prevent “flag graveyards”.

> Assumption: AshTrail already uses **build flavors** (Development vs Production) and may use **compile-time constants** for environment selection.
>
> Open question: Which mechanisms are currently implemented in-code (e.g., `--dart-define`, flavor-based entrypoints, config files)? This document describes the expected approach and what to verify in the repo.

---

### 2. Responsibilities

#### Owners
- **Feature author**
  - Proposes the flag, implements gating, adds tests, and sets removal criteria.
- **Reviewer**
  - Ensures gating is correct, tests exist, and cleanup policy is followed.
- **Maintainer**
  - Enforces periodic cleanup and prevents dead flags from persisting.

#### Core responsibilities
- Maintain a single, discoverable location for flag definitions (even if values are injected elsewhere).
- Ensure flags do not silently change persisted data formats without explicit migration/versioning.
- Ensure disabling a flag does not crash the app or strand user data.
- Ensure flags are observable in debug contexts (e.g., a diagnostics page or logs) without leaking secrets.

---

### 3. Data Structures (fields, types, constraints)

AshTrail should treat “flag definition” as metadata even if flags are implemented as raw constants.

#### 27.1 Flag Strategy — shared metadata model (documentation-level)
Use the following fields as the required information for any flag introduced:

- `key` (string, required)
  - Stable identifier (no spaces), e.g. `expRollingAnalyticsV2`
- `type` (enum: `bool`, `int`, `double`, `string`, required)
- `defaultValue` (type-matching, required)
- `scope` (enum: `compileTime`, `runtime`, required)
- `owner` (string, required)
- `createdAt` (date, required)
- `targetRemovalBy` (date, optional but strongly recommended)
- `description` (string, required)
- `gatingNotes` (string, optional)
  - What’s gated (UI only? domain logic? persistence?)
- `removalCriteria` (string, required)
  - What must be true for the flag to be deleted.
- `riskLevel` (enum: `low`, `medium`, `high`, required)
  - Used to enforce additional rules (see gating rules).

> Constraint: Any flag that gates persistence or sync behavior must be `riskLevel=high` and must include explicit rollback handling.

---

### 4. State & Flow (how data moves through the system)

#### 27.1.1 Compile-Time

**Definition**
- Compile-time flags are resolved at build time and cannot change while the app is running.
- Use cases:
  - Environment selection (dev/prod)
  - Stripping debug tooling from production
  - Hard-disabling experimental code paths for release builds
  - Enabling verbose logging / diagnostics only in dev

**Expected mechanisms (Flutter/Dart)**
- `--dart-define` values read via `const ...fromEnvironment(...)`
- Flavor-specific entrypoints / build configuration (Android productFlavors, iOS schemes)
- `kReleaseMode` / `kDebugMode` / `kProfileMode` for runtime-known build mode (still compile-time decided)

**Flow**
1. Build system injects values (flavor or `--dart-define`).
2. App startup reads compile-time constants.
3. Constants select:
   - Which services/adapters initialize
   - Which screens/tools are registered
   - Which code paths are reachable

**Hard rule**
- Compile-time flags may be used to exclude entire features from production artifacts.
- Do not use compile-time flags for user-facing toggles you expect to flip after release.

**Example pattern (illustrative)**
~~~dart
const bool enableDebugTools =
    bool.fromEnvironment('ASH_ENABLE_DEBUG_TOOLS', defaultValue: false);
~~~

> Open question: What are AshTrail’s current injected values (names and defaults)? Document the canonical list once confirmed in the repo.

#### 27.1.2 Runtime

**Definition**
- Runtime flags can be evaluated while the app runs and can change without rebuilding.
- Use cases:
  - Gradual rollout on a single device
  - Emergency kill-switch for risky behavior
  - Per-account enablement (if needed)

**Expected storage sources (choose one)**
- Local-only: persisted app settings (safe default for offline-first)
- Remote-config: fetched from backend and cached locally (requires explicit offline behavior)

**Flow**
1. App boot loads a runtime flag snapshot from local storage.
2. State layer exposes a read-only “flags view” to the UI/domain.
3. If remote-config exists:
   - Sync process refreshes flags in the background
   - New snapshot is persisted
   - Consumers update via provider/state refresh

**Hard rules**
- Runtime flag evaluation must be deterministic for a given snapshot.
- Runtime flags that affect persistence or sync must:
  - Be versioned
  - Have rollback rules
  - Be observable for debugging (e.g., included in exported diagnostics)

> Open questions:
> - Are runtime flags implemented today?
> - If yes, where are they stored, and how are they loaded into Riverpod?
> - If remote flags exist, how is offline behavior defined (stale TTL, failure fallback)?

---

### 5. Edge Cases & Failure Modes

#### Flag evaluation failures
- Missing key / parse error
  - Must fall back to `defaultValue` and log a debug warning in non-release builds.
- Conflicting sources (compile-time says off, runtime says on)
  - Compile-time wins if the code is compiled out / not reachable.
  - Otherwise define an explicit precedence order and document it.

#### Persistence and migration hazards (high risk)
- A flag changes:
  - schema fields written to local DB
  - Firestore document shape / sync semantics
  - aggregation derivations that are stored/cached
- Failure mode: disabling flag makes existing data unreadable or causes sync conflicts.

**Required mitigations**
- Any flag that impacts persisted formats must include:
  - forward-compat read logic (can read both shapes), or
  - migration with a version marker, or
  - explicit “flag cannot be disabled once enabled” behavior (documented and enforced)

#### Experimental UI gating pitfalls
- UI is hidden but routes/actions still reachable
  - Must gate navigation targets and any commands that mutate state.
- Partial gating creates “half-enabled” states
  - Prefer gating at a single composition root (feature module registration) vs scattered `if` checks.

---

### 6. Future Extensions (clearly labeled)

This section is non-binding; implement only if needed.

- Flag registry tooling
  - A generated page listing all flags, defaults, and current resolved values.
- Debug export bundle
  - Include current compile-time environment + runtime flag snapshot for bug reports.
- Automated cleanup checks (CI)
  - Fail PRs introducing flags without `removalCriteria`.
  - Warn when `targetRemovalBy` is exceeded.
- Safer experiment framework
  - Guardrails for “high-risk” flags:
    - Require migrations
    - Require rollback tests
    - Require explicit owner approval

---

### 27.2 Experimental Features

#### 27.2.1 Gating Rules

Experimental features must be gated based on risk level:

##### Low risk (UI-only; no persistence/sync impact)
- Allowed to gate at UI composition level.
- Must not write new persisted fields.
- Must be removable without data changes.

##### Medium risk (domain logic changes; derived calculations; analytics)
- Must include unit tests proving:
  - enabled behavior is correct
  - disabled behavior remains correct
- Must avoid storing derived outputs unless versioned.

##### High risk (persistence, sync, auth, account boundaries)
- Must include:
  - explicit rollback behavior
  - compatibility logic (read old + new forms), or a migration plan
  - integration test coverage including toggling scenarios

**Hard rule**
- “High risk” experiments cannot be “UI gated only”.
  - If the domain path exists, it must be gated at the domain boundary as well.

---

### 27.3 Cleanup Policy

#### 27.3.1 Flag Removal Criteria

Flags are temporary by default.

A flag must be removed when any of the following is true:
- The experiment is complete and the behavior is:
  - permanently adopted, or
  - permanently rejected.
- The flag has no active code paths (dead flag).
- The flag’s target removal date has passed and there is no documented extension.

**Removal checklist**
- Delete the flag definition (constant / config / key).
- Delete gated branches that are no longer used.
- Delete tests that only validate the removed branch, or rewrite tests to match the new permanent behavior.
- Remove any temporary UI controls or debug toggles.
- Verify migrations or dual-read logic are either:
  - no longer needed and removed, or
  - formalized as backward compatibility logic with version markers.

**Audit cadence (recommended)**
- Review all flags at least monthly.
- Any flag older than 90 days must either:
  - be removed, or
  - have a documented rationale + extended removal date.

---

### Assumptions & Open Questions (to resolve for implementation-accuracy)

- Are compile-time flags currently implemented via:
  - flavor entrypoints,
  - `--dart-define`,
  - or both?
- Is there any runtime flag mechanism implemented today?
  - If yes: where is the snapshot stored, and which provider exposes it?
- Are there existing “experiments” in the repo today that should be formalized as flags?
- What is the canonical naming convention for defines/flags (prefix, casing)?
- Do we need per-account runtime flags, or is global-per-device sufficient?

---

---

<!-- FILE: 28. Migration & Backward Compatibility.md -->

<a id="28-migration-&-backward-compatibility"></a>

## 28. Migration & Backward Compatibility

### 28.0 Overview

AshTrail is **offline-first** with a **local database as the source of truth** and Firestore as an optional sync/backup layer. Migration exists to:

- Preserve user data across app releases.
- Evolve local schemas (Isar) and remote document shapes (Firestore) without requiring data loss.
- Ensure older clients fail safely (or continue working) when newer data exists.

**Current status (from project documentation outline):**
- Isar schema changes are **manual and developer-managed** today (i.e., no fully automated, fully documented migration history yet).  
- Migration strategy must therefore prioritize **explicit versioning**, **safe defaults**, and **failure recovery**.

---

### 28.1 Local Schema Migration

#### 28.1.1 Version Detection

Local schema migration must answer two questions on startup (per account):

1. **What schema version is on disk?**
2. **What schema version does this build expect?**

Because AshTrail is multi-account, version detection must be **per account storage**, not global.

**Recommended sources of truth (pick one and be consistent):**
- **Isar schema version** (preferred): open Isar with a `schemaVersion` and a migration callback.
- **App-managed version stamp** (secondary): store `localSchemaVersion` alongside account metadata (e.g., in account-scoped settings / prefs).

**Required properties:**
- Version is a monotonically increasing integer.
- Version is read before any writes.
- Version is stored per account (since each account has an independent local store).

~~~text
Per-account migration decision (conceptual)

onAppStart:
  for each activeAccount:
    vDisk = readLocalSchemaVersion(account)
    vCode = CURRENT_LOCAL_SCHEMA_VERSION
    if vDisk == vCode: continue
    if vDisk > vCode: enter "downgrade" mode (see rollback strategy)
    else: runMigrations(account, from=vDisk, to=vCode)
~~~

---

#### 28.1.2 Migration Execution Model

**Principles**
- Migrations must be **explicit** (no silent breaking changes).
- Migrations must be **idempotent** when possible.
- Migrations must be **atomic** at the user-data level (either fully migrated or recoverable).

**Recommended structure**
- A migration registry keyed by integer version:
  - `vN -> vN+1` steps only (no giant “do everything” blob).
- Each step declares:
  - What collections are affected.
  - Whether the step is destructive.
  - Whether the step requires a backup.

~~~dart
// Pseudocode shape (not implementation-verified)
typedef MigrationStep = Future<void> Function(Isar isar);

final migrationSteps = <int, MigrationStep>{
  1: migrateV1ToV2,
  2: migrateV2ToV3,
};
~~~

**Execution constraints**
- Run migrations **before** starting sync.
- Block UI writes to the affected account until migration completes.
- Prefer showing a dedicated “Migrating account data…” screen if migration is non-trivial.

---

### 28.2 Remote Data Migration

Firestore is schemaless, so “migration” is primarily about **backward/forward compatible document evolution** and **sync logic compatibility**.

#### 28.2.1 Firestore Changes

**Rules for Firestore schema evolution**
- Prefer **additive changes**:
  - Add new optional fields.
  - Do not rename/remove fields until you have an explicit compatibility plan.
- Clients must:
  - Treat unknown fields as ignorable.
  - Treat missing fields as defaultable.
- Any breaking semantic change should be gated behind:
  - A `docVersion` field, or
  - A feature flag / protocol version in sync metadata.

**Recommended document version stamp**
- Add an integer `docVersion` (or equivalent) on each synced document type **or** within a per-account sync metadata document.
- Version is written by new clients; old clients ignore it.

~~~json
{
  "docVersion": 3,
  "createdAt": "2025-12-29T17:21:10Z",
  "updatedAt": "2025-12-29T17:22:45Z",
  "payload": { "...": "..." }
}
~~~

**Handling truly breaking changes**
If a field rename or type change is unavoidable:
- Support a **dual-read** period:
  - Read `newField` if present, else fall back to `oldField`.
- Support a **dual-write** period (optional but safest):
  - Write both fields for a period so older clients still function.
- After sufficient deprecation time, stop writing the old field.

**No server-side jobs constraint**
Project constraints indicate “no server-side jobs” as an operational constraint (at least currently). Therefore:
- Remote “backfills” should be avoided.
- If a backfill becomes necessary, treat it as a **future extension** and document the operational change explicitly.

---

### 28.3 User Impact

#### 28.3.1 Downtime Expectations

**Local migration**
- Expected downtime is **only on first launch after upgrading** and **per account**.
- Typical user experience:
  - App opens → detects schema mismatch → blocks account usage → migrates → resumes.
- The “downtime” is device-local (no Firestore requirement), unless the chosen recovery path involves re-sync.

**Remote changes**
- Properly additive Firestore changes should cause **zero downtime**.
- If sync protocol changes, users may see:
  - Sync paused with a “requires upgrade” error (preferred to corruption).
  - Partial sync until both sides converge on compatible logic.

**Minimum UX requirements**
- A clear message when migration is happening and which account is affected.
- A clear error when migration fails:
  - What happened
  - Whether data is safe
  - What the user can do next (retry / restore / export / reset)

---

### 28.4 Rollback Strategy

Rollback is about **failure recovery**, not “downgrading the app” (downgrades are inherently hostile to forward-only schemas).

#### 28.4.1 Failure Recovery

**Local migration failure recovery (preferred order)**
1. **Transactional/atomic migration** (if supported by the operation pattern):
   - Ensure partial writes can be detected and safely retried.
2. **Pre-migration backup snapshot** (recommended for any destructive step):
   - Copy/export the local database (or critical collections) before running destructive migrations.
3. **Restore from backup**
   - If migration fails, restore snapshot and keep the account in “migration required” mode.
4. **Rebuild from remote (last resort)**
   - If Firestore is enabled and trusted enough:
     - Wipe local store for the account
     - Re-sync from remote
   - This must be explicit because local is normally authoritative.

**Downgrade handling**
If the app detects `vDisk > vCode` (local schema newer than this build supports):
- Do not attempt to “reverse migrate” silently.
- Fail safe:
  - Mark account as “requires newer app version”
  - Block writes
  - Allow export if possible (read-only tools)

~~~text
Downgrade safe behavior (conceptual)
- Show: "This account’s data was created by a newer version of AshTrail."
- Actions:
  - Update app
  - Export data (if supported)
  - Remove account from device (explicit destructive)
~~~

**Remote rollback (Firestore)**
Because Firestore is schemaless, rollback is typically about client logic:
- Keep changes backward compatible as long as possible.
- If dual-write was used, stopping new writes is usually sufficient.
- Avoid deleting fields remotely unless there is a strong reason and a documented plan.

---

### 28.5 Edge Cases & Failure Modes

- **Skipped versions** (e.g., v1 → v5 upgrade):
  - Must apply migrations sequentially.
- **Partial migration due to crash / OS kill**:
  - Must detect “in-progress” marker and resume or restore.
- **Insufficient disk space for backup**:
  - Migration must fail before destructive steps.
- **Local corruption detected pre-migration**:
  - Offer recovery options: export what’s readable, reset local, re-sync (if enabled).
- **Multi-account isolation breach**:
  - A migration must never read/write another account’s database or version stamp.
- **Firestore shape drift**:
  - Remote docs missing expected fields must not crash sync; default or quarantine invalid docs.

---

### 28.6 Future Extensions

- **Formal migration ledger**
  - Document every schema version with:
    - Date introduced
    - Collections impacted
    - Data transformation notes
- **Migration test harness**
  - Fixture databases for each historical schema version + automated upgrade tests.
- **Structured “repair mode”**
  - A dedicated screen/tooling for:
    - Exporting raw data
    - Rebuilding derived aggregates
    - Re-syncing a single account
- **Optional server-side backfill**
  - Only if operational constraints change (introduces costs and reliability concerns).
  - Must be gated behind an ADR and explicit deployment documentation.

---

### Assumptions & Open Questions (Migration)

**Assumptions**
- Isar is the local persistence layer and schema changes are manual today.
- Firestore is the only remote backend currently planned.

**Open Questions**
- Where is the **current local schema version** defined in code (Isar `schemaVersion` vs app-managed stamp)?
- Is there an existing **migration registry** or are migrations handled ad-hoc per release?
- Is there an existing **backup/export** mechanism that can be reused for pre-migration snapshots?
- Do Firestore documents already include any **version/protocol markers**?
- What is the intended behavior when a user installs an older build over newer data (read-only/export vs hard block)?

---

---

<!-- FILE: 29. Observability & Diagnostics.md -->

<a id="29-observability-&-diagnostics"></a>

## 29. Observability & Diagnostics

### 1. Overview

Observability & Diagnostics covers the mechanisms used to:
- Understand how AshTrail is being used (locally, privacy-preserving)
- Diagnose issues during development and in the field
- Collect user-provided diagnostic artifacts (log bundles) without leaking sensitive data

This section exists because:
- A privacy-first app still needs actionable diagnostics
- Offline-first behavior makes “repro it on my machine” less reliable
- Multi-account data increases the risk of leaking identifiers if diagnostics aren’t explicitly designed

> Assumption: AshTrail avoids third-party telemetry by default and favors local-only diagnostics.  
> Open question: Is there any remote crash reporting (e.g., Crashlytics/Sentry) planned or currently used?

---

### 2. Responsibilities

#### 29.1 Metrics (Usage Metrics)
- Define what “usage metrics” mean in AshTrail (local counters/timestamps, not external analytics by default)
- Store metrics in a way that is:
  - Cheap to write
  - Safe to export (after redaction)
  - Optional and disable-able (feature-flag or build-mode gated)

#### 29.2 Debug Views (Internal Screens)
- Provide internal UI screens to:
  - Inspect local state and caches
  - Inspect sync state (if applicable)
  - Inspect logs and export a diagnostic bundle
- Ensure these screens are not available in production builds (or are strongly gated)

#### 29.3 User-Reported Issues (Log Bundles)
- Generate a diagnostic artifact that users can share (e.g., file export/share sheet)
- Include enough context to debug without including sensitive user content
- Support deterministic reproduction signals (versions, build flavor, device info, feature flags)

#### 29.4 Privacy Constraints (Data Redaction)
- Prevent leaking:
  - Account identifiers that can be tied back to a person
  - Auth tokens / refresh tokens / session cookies
  - Free-form user notes (if any exist)
  - Raw timestamps if they are considered sensitive for the use case (policy decision)

---

### 3. Data structures (fields, types, constraints)

> Note: Exact storage entities depend on the existing local DB schema. The structures below define recommended fields and constraints for a diagnostics subsystem. If AshTrail already has concrete entities for logs/metrics, replace these with the implementation-accurate structures.

#### 29.1 Usage metrics

**UsageMetric (conceptual)**
- `id`: string (unique; UUID recommended)
- `key`: string  
  - Example keys: `appLaunch`, `logCreate`, `exportStarted`, `exportCompleted`, `syncAttempted`
- `count`: int  
  - Monotonic non-negative
- `firstSeenAt`: datetime (optional)
- `lastSeenAt`: datetime (optional)
- `scope`: enum[`global`, `account`]  
  - `account` scope requires a stable but *redactable* reference to account
- `accountRef`: string?  
  - MUST NOT be a raw email/username/token  
  - Prefer: internal UUID (still redactable) or derived anonymized id

**Constraints**
- No metric should store free-form user input
- If per-account metrics exist, account identifiers must be redactable during export

#### 29.2 Debug view state

**DebugViewModel (conceptual UI state)**
- `isEnabled`: bool (should be false in production unless explicitly turned on)
- `sections`: enum[] (e.g., `logs`, `metrics`, `db`, `sync`, `featureFlags`, `device`)
- `filters`: json? (log level, time window, account scope)

#### 29.3 Log bundle contents

**LogBundleManifest (conceptual)**
- `bundleId`: string (UUID)
- `createdAt`: datetime
- `appVersion`: string
- `buildFlavor`: enum[`dev`, `prod`] (or project-defined flavors)
- `platform`: enum[`android`, `ios`]
- `osVersion`: string?
- `deviceModel`: string?
- `locale`: string?
- `timezone`: string?
- `enabledFlags`: string[]? (only flags that are safe to disclose)
- `redactionProfile`: enum[`strict`, `standard`] (policy choice)
- `files`: array of:
  - `path`: string (relative path inside bundle)
  - `sha256`: string? (optional integrity check)
  - `bytes`: int

**Bundle file types (recommended)**
- `manifest.json`
- `logs.ndjson` (or `logs.json`)
- `metrics.json`
- `sync_state.json` (if sync exists)
- `db_snapshot.json` (ONLY if safe and redacted; often too risky)

#### 29.4 Redaction configuration

**RedactionRule (conceptual)**
- `name`: string
- `type`: enum[`regex`, `jsonPath`, `keyMatch`]
- `pattern`: string
- `replacement`: string (default: `"[REDACTED]"`)
- `appliesTo`: enum[`logs`, `metrics`, `manifest`, `all`]

**RedactionProfile**
- `profile`: enum[`strict`, `standard`]
- `rules`: RedactionRule[]

---

### 4. State & flow (how data moves through the system)

#### 29.1 Usage metrics flow
1. App event occurs (launch, log creation, export, etc.)
2. Metric recorder increments a counter and updates `lastSeenAt`
3. Metrics are stored locally (DB or lightweight key-value store)
4. Debug view can display metrics
5. Export pipeline reads metrics and applies redaction (if any account scoping exists)
6. Metrics included in log bundle

**Open questions**
- Where are metrics stored today (Isar/SQLite/shared_preferences/other)?
- Are metrics intended to be per-account or global-only?

#### 29.2 Debug views flow (internal screens)
1. Debug entry point is enabled by:
   - Build mode (debug/profile only), and/or
   - Feature flag, and/or
   - Hidden gesture / secret menu (still risky in prod)
2. Debug screens read from:
   - Local DB
   - In-memory state (e.g., Riverpod providers)
   - Log buffer
3. Debug screens provide actions:
   - Copy-to-clipboard JSON
   - Export log bundle
   - Reset local caches (dangerous; should require confirmation)

**Failure mode requirement**
- Debug screens must not crash the app if underlying data is malformed; they should show partial results and errors.

#### 29.3 User-reported issues flow (log bundles)
1. User initiates “Create Diagnostics Bundle”
2. App builds `manifest.json` (version/build/device/flags)
3. App collects:
   - Logs (bounded window)
   - Metrics
   - Sync state (if applicable)
4. App runs redaction pass across collected artifacts
5. App packages bundle:
   - Preferred: `.zip`
   - Alternative: single `.json` with embedded arrays
6. App invokes platform share/export UI
7. User attaches bundle to a bug report (email, issue tracker, etc.)

**Open questions**
- What sharing mechanism is used (Android share sheet / iOS share sheet / in-app email)?
- Are bundles encrypted at rest before sharing, or only stored in temp storage?

#### 29.4 Redaction flow
1. Export pipeline enumerates all included artifacts
2. Applies redaction rules by artifact type
3. Validates output:
   - No known sensitive keys present (tokens, auth headers)
   - No emails/phone numbers (if that policy exists)
4. Writes redacted artifacts into bundle

---

### 5. Edge cases & failure modes

#### Metrics
- Counter corruption (negative or overflow)
  - Mitigation: clamp at `>= 0`; reset with note in logs
- Metrics store unavailable (DB locked, migration failure)
  - Mitigation: metrics become best-effort; do not block primary features

#### Debug views
- Debug screens accidentally available in production
  - Mitigation: compile-time gating + runtime checks
  - Add automated test/assertion that debug routes are absent in release builds
- Debug screens expose raw PII
  - Mitigation: debug UI should default to redacted display, with a “show raw” control available only in dev

#### Log bundles
- Bundle too large
  - Mitigation: bounded log ring buffer; time-window selection; size cap
- Bundle creation fails mid-way (disk full, permission denied)
  - Mitigation: partial bundle with manifest + error summary; surface actionable message
- Timezone/locale mismatch causing confusion during triage
  - Mitigation: include both local timestamps and UTC timestamps in manifest (policy decision)

#### Redaction
- Redaction misses a sensitive field due to new code paths
  - Mitigation: centralized redaction rules + unit tests with known “canary” strings
- Over-redaction makes bundle useless
  - Mitigation: profiles (`strict` vs `standard`) and explicit documentation of what is removed

---

### 6. Future extensions (clearly labeled)

#### Optional: Structured logging
- Move from unstructured strings to structured log events:
  - `eventName`, `level`, `timestamp`, `context` (json)
- Benefits:
  - Safer redaction
  - Easier filtering in debug views
  - Better export stability

#### Optional: Diagnostics “repro recipe”
- Include:
  - Recent navigation route history (redacted)
  - Last N domain events (e.g., “log created”, “sync attempted”)
- Helps reproduce bugs without needing raw user data

#### Optional: In-app issue reporting
- Flow:
  - User describes issue (free text)
  - App auto-attaches log bundle
  - User consents to include specific fields
- Requires strong privacy UX and explicit opt-in

#### Optional: Local “health checks”
- Simple checks with results included in bundle:
  - DB schema version
  - Pending sync queue length
  - Storage available
  - Clock drift estimate (if relevant)

---

### Assumptions & Open Questions (Summary)

### Assumptions
- Observability is local-first; exports are user-initiated
- Debug views are not available in production builds by default
- Log bundles are redacted before leaving the device

### Open Questions
- What logging library/mechanism is used today (and is there a bounded ring buffer)?
- Where are usage metrics stored and what is their scope (global vs per account)?
- Is any third-party crash reporting used (now or planned)?
- What is the exact export format (zip vs json) and what files are included?
- What is the official redaction policy (emails, timestamps, account ids, user notes)?

---

---

<!-- FILE: 30. Decommissioning & Data Deletion.md -->

<a id="30-decommissioning-&-data-deletion"></a>

## 30. Decommissioning & Data Deletion

### 30.0 Scope and Definitions

**Decommissioning** in AshTrail covers:
- Removing an account from the app (local-only).
- Deleting remote data tied to an account (remote).
- Clearing subsets of data (partial resets) without removing the account.

**Key terms**
- **Account**: A logical identity within AshTrail (may correspond to a Firebase Auth user, a local profile, or both).
- **Local data**: On-device database records, caches, preferences, derived analytics, and any stored credentials/tokens.
- **Remote data**: Backend-stored records (e.g., Firestore documents, Cloud Storage objects, server-side token state).
- **Tombstone**: A persisted marker indicating deletion (used for sync consistency).

> Assumption: AshTrail is offline-first and supports multiple accounts on a single device (based on prior docs).  
> Open question: What is the definitive source of truth for “Account” (purely local vs Firebase Auth-backed)?

---

### 30.1 Account Deletion

#### 30.1.1 Overview

Account deletion is the user-initiated process to remove an account and its data from AshTrail.

Two levels may exist:
- **Local-only delete**: Removes the account and all related data from the device.
- **Full delete (local + remote)**: Also deletes remote data associated with the account.

> Open question: Does the product currently expose both options, or only local removal?

---

### 30.1.2 Responsibilities

**UI / UX**
- Provide a clear entry point (e.g., Settings → Account → Delete).
- Display explicit warnings about irreversibility (see §30.3).
- Support a “local-only” vs “local + remote” choice if remote deletion exists.

**Domain / Application Layer**
- Ensure deletion is account-scoped (never affects other accounts on the same device).
- Ensure deletion is idempotent (safe to retry).
- Coordinate local cleanup steps in correct order.
- For remote deletion: initiate, track status, and reconcile offline behavior.

**Data Layer**
- Local database: perform scoped deletion by `accountId`.
- Secure storage: remove secrets/tokens for `accountId`.
- Cache layers: clear derived/aggregated views tied to `accountId`.
- Notification scheduling: cancel pending notifications for `accountId`.

**Sync / Remote**
- If remote deletion exists, enforce authorization and correctness:
  - Only the authenticated user (or privileged backend) can delete their dataset.
  - Prevent resurrection of deleted data from pending sync queues.

---

#### 30.1.3 Data Structures (conceptual)

> Note: Exact types/locations must be confirmed from implementation.

Minimum recommended internal models:

- **DeletionRequest**
  - `accountId: string` (required)
  - `scope: enum[localOnly, localAndRemote]` (required)
  - `requestedAt: datetime` (required)
  - `reason: string?` (optional; analytics/debug only)
  - `clientOperationId: string` (required; idempotency key)

- **DeletionState**
  - `phase: enum[idle, localInProgress, remoteInProgress, completed, failed]`
  - `lastError: string?`
  - `retryable: bool`

- **DeletionTombstone** (only if deletion must sync)
  - `accountId: string`
  - `deletedAt: datetime`
  - `clientOperationId: string`
  - `remoteAckAt: datetime?`

> Open questions:
> - Is there an existing “operation log” / outbox table for sync? If yes, deletion should be represented as an operation.
> - Is there a dedicated per-account “meta” doc/record suitable for a tombstone?

---

### 30.1.4 State & Flow

#### A) Local-only deletion flow

1. **User action**
   - User chooses “Delete account from this device” (local-only).
2. **Pre-flight**
   - Confirm the account exists locally.
   - Block concurrent operations for the account (e.g., sync, imports, edits).
3. **Stop background work**
   - Pause/cancel active sync for that account.
   - Cancel scheduled notifications for that account.
4. **Delete local data**
   - Delete all account-scoped entities (logs, settings, derived analytics, drafts, queued operations).
5. **Clear secrets**
   - Remove tokens, refresh secrets, cached auth state, encryption keys for the account (if per-account).
6. **Remove account from account registry**
   - Remove account entry from “known accounts” list.
7. **Finalize**
   - UI navigates away (e.g., to account picker).
   - App state is refreshed to ensure no providers are holding stale references.

**Post-condition**
- No local data remains that can identify the deleted account or restore its state.

#### B) Local + remote deletion flow (if supported)

1–4. Same as local-only, plus:
5. **Issue remote deletion**
   - Either:
     - Client requests deletion via a privileged backend endpoint (recommended), or
     - Client performs deletions directly (only feasible if security rules allow safe recursive deletes).
6. **Remote acknowledgement**
   - Confirm completion via backend response or state polling.
7. **Prevent resurrection**
   - Ensure no queued sync operations can re-upload old data:
     - Clear outbox before remote delete request, or
     - Write tombstone first and reject uploads server-side.

**Offline behavior**
- If offline, remote deletion cannot complete immediately.
- Recommended: treat as **two-step**:
  - Perform local deletion immediately.
  - Record a pending remote deletion intent (tombstone/outbox) to be sent when back online.

> Open questions (must be answered to finalize implementation-accurate docs):
> - Does AshTrail have a backend service capable of deleting Firestore collections recursively?
> - Is there a Cloud Function or API already used for privileged operations (e.g., token refresh system suggests some backend exists)?
> - What is the remote data model (collection paths) that must be deleted?

---

### 30.1.5 Edge Cases & Failure Modes

**Local cleanup partially fails**
- Example: DB write lock, corrupted storage, permission error.
- Required behavior:
  - Mark deletion as `failed` with actionable error.
  - Provide retry.
  - Ensure partially deleted account is not “usable” until repaired or fully removed.

**Concurrent operations**
- Sync running while deletion begins.
- Required behavior:
  - Mutual exclusion: a per-account lock or “maintenance mode” gate.
  - Stop-the-world for that account before destructive operations.

**Remote deletion fails after local deletion**
- User sees local account gone, but remote data remains.
- Options:
  - Show a “remote deletion pending/failed” status in a global diagnostics screen.
  - Provide a way to retry remote deletion (requires auth context; see below).

**Auth context lost**
- If remote deletion requires being signed in, but user removed auth state locally first.
- Required behavior:
  - Ensure remote delete is requested **before** wiping auth, or
  - Require the user to re-authenticate specifically to complete remote deletion.

**Multi-device**
- If the same account exists on another device:
  - Remote deletion should propagate (other device must observe the deletion and purge local state).
  - If remote deletion is not supported, local-only deletion should be clearly labeled as device-specific.

---

### 30.2 Partial Resets

#### 30.2.1 Overview

Partial resets remove subsets of data while keeping the account itself present and usable.

Common reset scopes:
- **Per-account wipe (data)**: Remove logs/entries and derived analytics for the selected account.
- **Per-account settings reset**: Restore defaults for that account’s preferences.
- **Cache-only clear**: Remove derived/temporary data without deleting primary logs.

> Open question: Which of these scopes are actually implemented/exposed in the UI?

---

#### 30.2.2 Responsibilities

- Provide explicit scope selection and preview of what will be deleted.
- Ensure reset is account-scoped.
- Ensure reset is idempotent and safe to retry.
- Decide how reset interacts with remote sync:
  - Local-only reset vs synced deletion of remote logs.

---

#### 30.2.3 Data Structures (conceptual)

- **ResetRequest**
  - `accountId: string` (required)
  - `scope: enum[logsOnly, settingsOnly, cachesOnly, everythingButAccount]` (required)
  - `requestedAt: datetime` (required)
  - `clientOperationId: string` (required)

> Open question: Is there an existing “settings version” mechanism? If so, resets should bump a version.

---

#### 30.2.4 State & Flow: Per-Account Wipe

1. User selects account → chooses reset scope.
2. Pre-flight:
   - Stop per-account sync + background operations.
3. Execute scoped deletion:
   - Logs: delete all entities keyed by `accountId`.
   - Derived analytics: delete computed aggregates/histograms for `accountId`.
   - Caches: clear in-memory + persisted caches.
4. Post:
   - Recompute derived data as needed (or lazily on next view).
   - Resume sync if applicable.

**Remote sync considerations**
- If the wipe is intended to delete remote logs too:
  - Represent as a synced operation (outbox) or a backend “wipe account data” request.
  - Ensure other devices also purge via tombstone/version gating.

---

### 30.3 Irreversibility Guarantees

#### 30.3.1 Overview

AshTrail must treat deletion and destructive resets as irreversible from the user’s perspective.

**Guarantee definition**
- After a successful operation:
  - Deleted local data cannot be restored by the app.
  - If remote deletion exists and completes, remote data cannot be restored by the app.

> Important distinction: If OS-level backups (iCloud/Google) exist, those can reintroduce data unless explicitly addressed.  
> Open question: Does AshTrail opt-out of backups for local databases / secure data?

---

#### 30.3.2 User Warnings

Minimum required warnings (wording may vary; meaning must not):
- “This deletes data permanently.”
- “This cannot be undone.”
- If local-only: “This only removes data from this device.”
- If remote: “This deletes data from the server and all devices.”

Recommended safety UX:
- Require explicit confirmation step:
  - Checkbox + “Delete” button enabled only after acknowledgement, or
  - Require typing a confirmation string (e.g., `DELETE`) for full deletion.
- Show what will be deleted:
  - Count of logs/entries (if cheap to compute).
  - Date range of data affected (optional).
- Show what will remain (for partial resets).

---

#### 30.3.3 Edge Cases & Failure Modes

**User cancels mid-flow**
- If cancellation occurs after local deletion started:
  - Operation should continue to completion (don’t leave a half-deleted zombie account).
  - UI should reflect “in progress” until done.

**Unexpected app termination**
- If the app is killed mid-delete:
  - On next startup, detect incomplete delete and resume/finish.
  - Requires durable “DeletionState” persisted before starting destructive steps.

**Remote eventual consistency**
- If remote deletion is asynchronous:
  - UI should state: “Remote deletion pending.”
  - Provide status + retry path.

---

### 30.4 Future Extensions (clearly labeled)

- **Backend-driven deletion**
  - Add a privileged API endpoint for:
    - Recursive Firestore deletes
    - Storage object deletes
    - Token/session invalidation
- **Deletion tombstones + sync propagation**
  - Allow other devices to detect deletion and self-purge.
- **Data retention window**
  - Optional “cooldown” for accidental deletes (soft-delete with retention), if product requirements allow.
  - Would require careful UX to avoid contradicting “irreversible” messaging.
- **Export-before-delete**
  - Offer export flow (CSV/JSON) immediately before deletion or reset.
- **Compliance mode**
  - Add explicit guarantees/logs for “right to be forgotten” style requirements if needed.

---

### 30.5 Open Questions (must be answered to finalize implementation-accurate docs)

1. Does AshTrail currently support **remote** deletion, or only local removal?
2. What is the **remote datastore** (Firestore paths, Storage buckets) for account-scoped data?
3. Is there a **backend service** (Cloud Functions/API) capable of privileged deletes?
4. Is there an **outbox/operation log** pattern used for sync, and can deletion be represented as an operation?
5. Where are per-account secrets stored (secure storage keying scheme), and are there per-account encryption keys?
6. Does the app opt-out of OS backups for local DB files (to prevent “deleted data reappearing”)?
